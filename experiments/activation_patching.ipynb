{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ec5a25-ac58-4967-ac6b-71d336d39946",
   "metadata": {},
   "source": [
    "# Activation patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4433029-251e-49bd-9c7b-849624e7181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.set_grad_enabled(mode=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dawnet.inspector import LLMInspector\n",
    "from dawnet.tokens import Tokens\n",
    "from dawnet import op\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5106075d-ea19-4dde-8cf0-384660ea9369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7241557e63ab4e9c85f46b175a3b9370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen3-4B-Thinking-2507\"\n",
    "device = torch.device(\"mps\")\n",
    "insp = LLMInspector.from_hf(model_id).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ffd00a05-b679-4da3-9e41-63057cb3009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_PROMPT = \"When John and Mary went to the store, John gave the bag to\"\n",
    "CORRUPTED_PROMPT = \"When John and Mary went to the store, she gave the bag to\"\n",
    "TARGET_TOKEN = 9\n",
    "CLS_TRUE = 3757\n",
    "CLS_FALSE = 10244\n",
    "\n",
    "# CLEAN_PROMPT = \"Robert woke up at 8:00am while Samuel woke up at 6:00am, so the person woke up later is\"\n",
    "# CORRUPTED_PROMPT = \"Robert woke up at 8:00am while Samuel woke up at 9:00am, so the person woke up later is\"\n",
    "# TARGET_TOKEN = 16\n",
    "# CLS_TRUE = 8397\n",
    "# CLS_FALSE = 31907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "425935f1-8d38-4f69-8024-9d746e9cb12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([29, 151936])): (tensor(8397, device='mps:0'), ' Robert')\n"
     ]
    }
   ],
   "source": [
    "with insp.ctx(detach_state=False) as clean_state:\n",
    "    clean_output = insp.infer(CLEAN_PROMPT, chat=False, use_original=True)\n",
    "print(clean_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a4774377-c21a-4be2-8069-5711616526f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([29, 151936])): (tensor(32671, device='mps:0'), ' ______')\n"
     ]
    }
   ],
   "source": [
    "with insp.ctx(detach_state=False) as corrupted_state:\n",
    "    corrupted_output = insp.infer(CORRUPTED_PROMPT, chat=False, use_original=True)\n",
    "print(corrupted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9aef5c3a-efbf-4729-bbf2-b66a031a47f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4500, device='mps:0') tensor(15.9206, device='mps:0')\n",
      "tensor(11.4763, device='mps:0') tensor(12.3267, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(clean_output.logits[-1,31907], clean_output.logits[-1,8397])\n",
    "print(corrupted_output.logits[-1,31907], corrupted_output.logits[-1,8397])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ad46326d-8ac2-40a4-baba-f9440a320e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .jp-OutputArea-output:has(.token-container) {\n",
       "        overflow: visible !important;\n",
       "    }\n",
       "\n",
       "    .token-container {\n",
       "        font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'source-code-pro', monospace;\n",
       "        font-size: 12px;\n",
       "        line-height: 1.2;\n",
       "        padding: 20px;\n",
       "        background-color: #ffffff;\n",
       "        border: 1px solid #ddd;\n",
       "        border-radius: 8px;\n",
       "        max-width: 95%;\n",
       "        overflow-wrap: break-word;\n",
       "        white-space: pre-wrap;\n",
       "        color: #000000;\n",
       "    }\n",
       "    .token {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        cursor: pointer;\n",
       "        padding: 1px;\n",
       "        margin: 0;\n",
       "        border-radius: 3px;\n",
       "        transition: background-color 0.2s;\n",
       "        color: #000000;\n",
       "        white-space: pre;\n",
       "        vertical-align: top;\n",
       "        border: 1px solid transparent;\n",
       "        font-size: inherit;\n",
       "        line-height: inherit;\n",
       "    }\n",
       "    .token:hover {\n",
       "        background-color: #ffeb3b;\n",
       "        border-color: #fbc02d;\n",
       "    }\n",
       "    .token-newline {\n",
       "        position: relative;\n",
       "        display: inline-block;\n",
       "        cursor: pointer;\n",
       "        padding: 1px 4px;\n",
       "        margin: 0;\n",
       "        border-radius: 3px;\n",
       "        transition: background-color 0.2s;\n",
       "        background-color: #ffffff;\n",
       "        border: 1px solid #90caf9;\n",
       "        font-size: 11px;\n",
       "        vertical-align: middle;\n",
       "        color: #1976d2;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "    .token-newline:hover {\n",
       "        background-color: #bbdefb;\n",
       "        border-color: #42a5f5;\n",
       "    }\n",
       "    .token-tooltip {\n",
       "        visibility: hidden;\n",
       "        position: absolute;\n",
       "        background-color: #333;\n",
       "        color: #fff;\n",
       "        text-align: left;\n",
       "        padding: 8px 12px;\n",
       "        border-radius: 6px;\n",
       "        z-index: 1000;\n",
       "        top: 125%;\n",
       "        left: 50%;\n",
       "        transform: translateX(-50%);\n",
       "        white-space: nowrap;\n",
       "        opacity: 0;\n",
       "        transition: opacity 0.3s;\n",
       "        font-size: 12px;\n",
       "        box-shadow: 0 2px 8px rgba(0,0,0,0.2);\n",
       "    }\n",
       "    .token-tooltip::after {\n",
       "        content: \"\";\n",
       "        position: absolute;\n",
       "        bottom: 100%;\n",
       "        left: 50%;\n",
       "        margin-left: -5px;\n",
       "        border-width: 5px;\n",
       "        border-style: solid;\n",
       "        border-color: transparent transparent #333 transparent;\n",
       "    }\n",
       "    .token:hover .token-tooltip, .token-newline:hover .token-tooltip {\n",
       "        visibility: visible;\n",
       "        opacity: 1;\n",
       "    }\n",
       "    .token-info {\n",
       "        display: block;\n",
       "        margin: 2px 0;\n",
       "    }\n",
       "</style>\n",
       "<div class=\"token-container\">\n",
       "<span class=\"token\">When<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 0</span><span class=\"token-info\"><strong>Token ID:</strong> 4498</span><span class=\"token-info\"><strong>Token Text:</strong> When</span></span></span><span class=\"token\"> John<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 1</span><span class=\"token-info\"><strong>Token ID:</strong> 3757</span><span class=\"token-info\"><strong>Token Text:</strong>  John</span></span></span><span class=\"token\"> and<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 2</span><span class=\"token-info\"><strong>Token ID:</strong> 323</span><span class=\"token-info\"><strong>Token Text:</strong>  and</span></span></span><span class=\"token\"> Mary<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 3</span><span class=\"token-info\"><strong>Token ID:</strong> 10244</span><span class=\"token-info\"><strong>Token Text:</strong>  Mary</span></span></span><span class=\"token\"> went<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 4</span><span class=\"token-info\"><strong>Token ID:</strong> 3937</span><span class=\"token-info\"><strong>Token Text:</strong>  went</span></span></span><span class=\"token\"> to<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 5</span><span class=\"token-info\"><strong>Token ID:</strong> 311</span><span class=\"token-info\"><strong>Token Text:</strong>  to</span></span></span><span class=\"token\"> the<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 6</span><span class=\"token-info\"><strong>Token ID:</strong> 279</span><span class=\"token-info\"><strong>Token Text:</strong>  the</span></span></span><span class=\"token\"> store<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 7</span><span class=\"token-info\"><strong>Token ID:</strong> 3553</span><span class=\"token-info\"><strong>Token Text:</strong>  store</span></span></span><span class=\"token\">,<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 8</span><span class=\"token-info\"><strong>Token ID:</strong> 11</span><span class=\"token-info\"><strong>Token Text:</strong> ,</span></span></span><span class=\"token\"> she<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 9</span><span class=\"token-info\"><strong>Token ID:</strong> 1340</span><span class=\"token-info\"><strong>Token Text:</strong>  she</span></span></span><span class=\"token\"> gave<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 10</span><span class=\"token-info\"><strong>Token ID:</strong> 6551</span><span class=\"token-info\"><strong>Token Text:</strong>  gave</span></span></span><span class=\"token\"> the<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 11</span><span class=\"token-info\"><strong>Token ID:</strong> 279</span><span class=\"token-info\"><strong>Token Text:</strong>  the</span></span></span><span class=\"token\"> bag<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 12</span><span class=\"token-info\"><strong>Token ID:</strong> 8968</span><span class=\"token-info\"><strong>Token Text:</strong>  bag</span></span></span><span class=\"token\"> to<span class=\"token-tooltip\"><span class=\"token-info\"><strong>Position:</strong> 13</span><span class=\"token-info\"><strong>Token ID:</strong> 311</span><span class=\"token-info\"><strong>Token Text:</strong>  to</span></span></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = Tokens([insp.tokenizer.encode(CORRUPTED_PROMPT)], insp.tokenizer)\n",
    "tokens.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf922012-6834-4205-88d9-ecb3344ecd57",
   "metadata": {},
   "source": [
    "## Patch a single activation\n",
    "\n",
    "Select the appropriate `name_regex` to handle the activation patching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22fba3-238c-42d2-8b0b-9e2d7ea88916",
   "metadata": {},
   "source": [
    "### Single model, 2 different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f4b81e88-aa1e-4408-bf33-226eca21d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.0', 'model.layers.1', 'model.layers.2', 'model.layers.3', 'model.layers.4', 'model.layers.5', 'model.layers.6', 'model.layers.7', 'model.layers.8', 'model.layers.9', 'model.layers.10', 'model.layers.11', 'model.layers.12', 'model.layers.13', 'model.layers.14', 'model.layers.15', 'model.layers.16', 'model.layers.17', 'model.layers.18', 'model.layers.19', 'model.layers.20', 'model.layers.21', 'model.layers.22', 'model.layers.23', 'model.layers.24', 'model.layers.25', 'model.layers.26', 'model.layers.27', 'model.layers.28', 'model.layers.29', 'model.layers.30', 'model.layers.31', 'model.layers.32', 'model.layers.33', 'model.layers.34', 'model.layers.35']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dawnet.op.GetOutput at 0x751138e60>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp.remove_all()\n",
    "name_regex = r\"model.layers.\\d+$\"    # used for getting\n",
    "name_pattern = \"model.layers.{layer_idx}\"      # used for substituting\n",
    "insp.add(op.GetOutput(), name_regex=name_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cccfe635-56e6-4f7d-9b01-7d7e2814f8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([14, 151936])): (tensor(10244, device='mps:0'), ' Mary')\n"
     ]
    }
   ],
   "source": [
    "# get the tokens from some place\n",
    "with insp.ctx(detach_state=True) as clean_state:\n",
    "    clean_output = insp.infer(CLEAN_PROMPT, chat=False)\n",
    "print(clean_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d3715c05-915a-4747-b6b6-cfc2d9f226a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 151936])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_output._logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c6a61359-7510-401f-b0bd-b56e9a7d10c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0416e+01, -3.0249e+00,  2.3518e+00,  ...,  3.2380e-01,\n",
       "          -1.7276e-01,  6.2741e-02],\n",
       "         [ 3.9990e+00, -1.4887e+00,  1.0076e+00,  ...,  2.5246e-01,\n",
       "          -5.8601e-02, -1.3308e-01],\n",
       "         [ 4.1106e+00, -7.9101e-01,  9.2293e-01,  ...,  1.1524e-01,\n",
       "          -6.3957e-02, -2.4922e-02],\n",
       "         ...,\n",
       "         [ 5.6527e+00, -1.0616e+00,  1.4061e+00,  ..., -2.4720e-03,\n",
       "          -1.3973e-03,  9.8506e-03],\n",
       "         [ 2.3397e+00, -1.2324e+00,  8.9781e-01,  ..., -2.4272e-02,\n",
       "           5.9846e-02,  6.6062e-02],\n",
       "         [ 2.2038e+00, -6.1032e-01,  6.4810e-01,  ...,  2.0979e-02,\n",
       "           6.9858e-02,  1.2590e-02]]], device='mps:0')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_state['output']['model.layers.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "41d0a9f5-dbde-47e7-b19b-3a338016a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.0']\n",
      "Added to layer ['model.layers.1']\n",
      "Added to layer ['model.layers.2']\n",
      "Added to layer ['model.layers.3']\n",
      "Added to layer ['model.layers.4']\n",
      "Added to layer ['model.layers.5']\n",
      "Added to layer ['model.layers.6']\n",
      "Added to layer ['model.layers.7']\n",
      "Added to layer ['model.layers.8']\n",
      "Added to layer ['model.layers.9']\n",
      "Added to layer ['model.layers.10']\n",
      "Added to layer ['model.layers.11']\n",
      "Added to layer ['model.layers.12']\n",
      "Added to layer ['model.layers.13']\n",
      "Added to layer ['model.layers.14']\n",
      "Added to layer ['model.layers.15']\n",
      "Added to layer ['model.layers.16']\n",
      "Added to layer ['model.layers.17']\n",
      "Added to layer ['model.layers.18']\n",
      "Added to layer ['model.layers.19']\n",
      "Added to layer ['model.layers.20']\n",
      "Added to layer ['model.layers.21']\n",
      "Added to layer ['model.layers.22']\n",
      "Added to layer ['model.layers.23']\n",
      "Added to layer ['model.layers.24']\n",
      "Added to layer ['model.layers.25']\n",
      "Added to layer ['model.layers.26']\n",
      "Added to layer ['model.layers.27']\n",
      "Added to layer ['model.layers.28']\n",
      "Added to layer ['model.layers.29']\n",
      "Added to layer ['model.layers.30']\n",
      "Added to layer ['model.layers.31']\n",
      "Added to layer ['model.layers.32']\n",
      "Added to layer ['model.layers.33']\n",
      "Added to layer ['model.layers.34']\n",
      "Added to layer ['model.layers.35']\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "for layer_idx in range(len(insp.model.model.layers)):\n",
    "    layer_name = name_pattern.format(layer_idx=layer_idx)\n",
    "    insp.remove_all()\n",
    "    set_op = op.SetOutput()\n",
    "    insp.add(set_op, name=layer_name)\n",
    "    for target_token in range(len(insp.tokenizer.encode(CORRUPTED_PROMPT))):\n",
    "        def output_fn(obj):\n",
    "            obj[0,target_token] = clean_state['output'][layer_name][0,target_token]\n",
    "            return obj\n",
    "        with insp.ctx([set_op.run_params(output_fn=output_fn)]):\n",
    "            corrupted_output = insp.infer(CORRUPTED_PROMPT, chat=False)\n",
    "            if layer_name not in result:\n",
    "                result[layer_name] = []\n",
    "            result[layer_name].append((\n",
    "                corrupted_output.logits[-1][CLS_TRUE].item(),\n",
    "                corrupted_output.logits[-1][CLS_FALSE].item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "50f63b98-2484-4c8b-92aa-3ad86e34f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.379772663116455 15.60390567779541\n",
      "model.layers.0 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.1 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.2 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.3 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.4 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.5 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.6 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.7 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.8 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.9 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.10 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.11 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.12 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.13 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.14 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.15 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.16 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.17 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.18 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.19 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.20 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.21 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.22 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.23 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.24 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.25 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.26 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.27 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.28 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.29 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.30 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.31 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.32 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.33 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.34 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.35 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n"
     ]
    }
   ],
   "source": [
    "print(clean_output.logits[-1][CLS_TRUE].item(), clean_output.logits[-1][CLS_FALSE].item())\n",
    "for key, value in result.items():\n",
    "    r = [\"John\" if o0 > o1 else \"Mary\" for (o0, o1) in value]\n",
    "    print(key, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bea513-99e0-4f9a-ac92-22514f1be11a",
   "metadata": {},
   "source": [
    "### 2 models of similar architecture, 2 different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fac88b04-1216-4b8a-9f73-774c7a85e3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daf01ef23ae4b3b84fb309a33c9cfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id2 = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "insp2 = LLMInspector.from_hf(model_id2).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f27fe168-2867-426a-93c1-7c3018470fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.0', 'model.layers.1', 'model.layers.2', 'model.layers.3', 'model.layers.4', 'model.layers.5', 'model.layers.6', 'model.layers.7', 'model.layers.8', 'model.layers.9', 'model.layers.10', 'model.layers.11', 'model.layers.12', 'model.layers.13', 'model.layers.14', 'model.layers.15', 'model.layers.16', 'model.layers.17', 'model.layers.18', 'model.layers.19', 'model.layers.20', 'model.layers.21', 'model.layers.22', 'model.layers.23', 'model.layers.24', 'model.layers.25', 'model.layers.26', 'model.layers.27', 'model.layers.28', 'model.layers.29', 'model.layers.30', 'model.layers.31', 'model.layers.32', 'model.layers.33', 'model.layers.34', 'model.layers.35']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dawnet.op.GetOutput at 0x75122e660>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp2.remove_all()\n",
    "name_regex = r\"model.layers.\\d+$\"    # used for getting\n",
    "name_pattern = \"model.layers.{layer_idx}\"      # used for substituting\n",
    "insp2.add(op.GetOutput(), name_regex=name_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d8696-82e2-4e6a-9768-d961faf2551b",
   "metadata": {},
   "source": [
    "#### Understand the activation difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6f96609f-dd71-4c1e-a1d7-9781c8c5a733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([14, 151936])): (tensor(10244, device='mps:0'), ' Mary')\n"
     ]
    }
   ],
   "source": [
    "# get the tokens from some place\n",
    "with insp2.ctx(detach_state=True) as clean_state2:\n",
    "    clean_output2 = insp2.infer(CLEAN_PROMPT, chat=False)\n",
    "print(clean_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1ec6847f-8aa4-40e1-a563-68a09adb29b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([14, 151936])): (tensor(3757, device='mps:0'), ' John')\n"
     ]
    }
   ],
   "source": [
    "# get the corrupted tokens\n",
    "with insp2.ctx(detach_state=True) as corrupted_state2:\n",
    "    corrupted_output2 = insp2.infer(CORRUPTED_PROMPT, chat=False)\n",
    "print(corrupted_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2e2f601c-06cf-4ccc-a835-b4f13a4ea2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([14, 151936])): (tensor(10244, device='mps:0'), ' Mary')\n"
     ]
    }
   ],
   "source": [
    "with insp.ctx(detach_state=True) as clean_state:\n",
    "    clean_output = insp.infer(CLEAN_PROMPT, chat=False)\n",
    "print(clean_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1211bb8d-58e6-490e-a27b-966665777bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogitTensors (shape torch.Size([14, 151936])): (tensor(3757, device='mps:0'), ' John')\n"
     ]
    }
   ],
   "source": [
    "with insp.ctx(detach_state=True) as corrupted_state:\n",
    "    corrupted_output = insp.infer(CORRUPTED_PROMPT, chat=False)\n",
    "print(corrupted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5e3a6e2a-bed6-4aff-bca3-140421f7178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff2[0, TARGET_TOKEN]=tensor([ 2.4015, -1.0581, -0.0791,  ...,  0.5775,  0.0426, -0.0406],\n",
      "       device='mps:0')\n",
      "diff1[0, TARGET_TOKEN]=tensor([ 2.3054, -1.0591, -0.0107,  ...,  0.4486,  0.0466, -0.0414],\n",
      "       device='mps:0')\n",
      "torch.cosine_similarity(diff1[0, TARGET_TOKEN], diff2[0, TARGET_TOKEN], dim=0)=tensor(0.9831, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"{diff2[0, TARGET_TOKEN]=}\")\n",
    "print(f\"{diff1[0, TARGET_TOKEN]=}\")\n",
    "print(f\"{torch.cosine_similarity(diff1[0, TARGET_TOKEN], diff2[0, TARGET_TOKEN], dim=0)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8add2ef3-94b7-4b81-8861-9cd2299b02de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0., device='mps:0')\n",
      "1 tensor(0., device='mps:0')\n",
      "2 tensor(0., device='mps:0')\n",
      "3 tensor(0., device='mps:0')\n",
      "4 tensor(0., device='mps:0')\n",
      "5 tensor(0., device='mps:0')\n",
      "6 tensor(0., device='mps:0')\n",
      "7 tensor(0., device='mps:0')\n",
      "8 tensor(0., device='mps:0')\n",
      "9 tensor(0.9831, device='mps:0')\n",
      "10 tensor(0.9538, device='mps:0')\n",
      "11 tensor(0.2265, device='mps:0')\n",
      "12 tensor(0.9245, device='mps:0')\n",
      "13 tensor(0.9091, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for token_idx in range(len(insp.tokenizer.encode(CORRUPTED_PROMPT))):\n",
    "    print(token_idx, torch.cosine_similarity(diff1[0, token_idx], diff2[0, token_idx], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "12c7759f-0fbb-44a6-8c15-dd2afddcca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.9926, device='mps:0')\n",
      "1 tensor(0.9892, device='mps:0')\n",
      "2 tensor(0.9837, device='mps:0')\n",
      "3 tensor(0.9831, device='mps:0')\n",
      "4 tensor(0.9805, device='mps:0')\n",
      "5 tensor(0.9771, device='mps:0')\n",
      "6 tensor(0.9704, device='mps:0')\n",
      "7 tensor(0.9664, device='mps:0')\n",
      "8 tensor(0.9597, device='mps:0')\n",
      "9 tensor(0.9600, device='mps:0')\n",
      "10 tensor(0.9644, device='mps:0')\n",
      "11 tensor(0.9652, device='mps:0')\n",
      "12 tensor(0.9624, device='mps:0')\n",
      "13 tensor(0.9605, device='mps:0')\n",
      "14 tensor(0.9583, device='mps:0')\n",
      "15 tensor(0.9542, device='mps:0')\n",
      "16 tensor(0.9559, device='mps:0')\n",
      "17 tensor(0.9520, device='mps:0')\n",
      "18 tensor(0.9496, device='mps:0')\n",
      "19 tensor(0.9473, device='mps:0')\n",
      "20 tensor(0.9478, device='mps:0')\n",
      "21 tensor(0.9442, device='mps:0')\n",
      "22 tensor(0.9563, device='mps:0')\n",
      "23 tensor(0.9573, device='mps:0')\n",
      "24 tensor(0.9553, device='mps:0')\n",
      "25 tensor(0.9520, device='mps:0')\n",
      "26 tensor(0.9512, device='mps:0')\n",
      "27 tensor(0.9480, device='mps:0')\n",
      "28 tensor(0.9481, device='mps:0')\n",
      "29 tensor(0.9426, device='mps:0')\n",
      "30 tensor(0.9363, device='mps:0')\n",
      "31 tensor(0.9254, device='mps:0')\n",
      "32 tensor(0.9206, device='mps:0')\n",
      "33 tensor(0.9101, device='mps:0')\n",
      "34 tensor(0.8973, device='mps:0')\n",
      "35 tensor(0.8135, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for layer_idx in range(36):\n",
    "    diff2 = clean_state2[\"output\"][f\"model.layers.{layer_idx}\"] - corrupted_state2[\"output\"][f\"model.layers.{layer_idx}\"]\n",
    "    diff1 = clean_state[\"output\"][f\"model.layers.{layer_idx}\"] - corrupted_state[\"output\"][f\"model.layers.{layer_idx}\"]\n",
    "    print(layer_idx, torch.cosine_similarity(diff1[0, TARGET_TOKEN], diff2[0, TARGET_TOKEN], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1990be6a-d966-4845-be17-52f8c4b317fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.0']\n",
      "Added to layer ['model.layers.1']\n",
      "Added to layer ['model.layers.2']\n",
      "Added to layer ['model.layers.3']\n",
      "Added to layer ['model.layers.4']\n",
      "Added to layer ['model.layers.5']\n",
      "Added to layer ['model.layers.6']\n",
      "Added to layer ['model.layers.7']\n",
      "Added to layer ['model.layers.8']\n",
      "Added to layer ['model.layers.9']\n",
      "Added to layer ['model.layers.10']\n",
      "Added to layer ['model.layers.11']\n",
      "Added to layer ['model.layers.12']\n",
      "Added to layer ['model.layers.13']\n",
      "Added to layer ['model.layers.14']\n",
      "Added to layer ['model.layers.15']\n",
      "Added to layer ['model.layers.16']\n",
      "Added to layer ['model.layers.17']\n",
      "Added to layer ['model.layers.18']\n",
      "Added to layer ['model.layers.19']\n",
      "Added to layer ['model.layers.20']\n",
      "Added to layer ['model.layers.21']\n",
      "Added to layer ['model.layers.22']\n",
      "Added to layer ['model.layers.23']\n",
      "Added to layer ['model.layers.24']\n",
      "Added to layer ['model.layers.25']\n",
      "Added to layer ['model.layers.26']\n",
      "Added to layer ['model.layers.27']\n",
      "Added to layer ['model.layers.28']\n",
      "Added to layer ['model.layers.29']\n",
      "Added to layer ['model.layers.30']\n",
      "Added to layer ['model.layers.31']\n",
      "Added to layer ['model.layers.32']\n",
      "Added to layer ['model.layers.33']\n",
      "Added to layer ['model.layers.34']\n",
      "Added to layer ['model.layers.35']\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "for layer_idx in range(len(insp.model.model.layers)):\n",
    "    layer_name = name_pattern.format(layer_idx=layer_idx)\n",
    "    insp.remove_all()\n",
    "    set_op = op.SetOutput()\n",
    "    insp.add(set_op, name=layer_name)\n",
    "    diff2 = clean_state2[\"output\"][f\"model.layers.{layer_idx}\"] - corrupted_state2[\"output\"][f\"model.layers.{layer_idx}\"]\n",
    "    for target_token in range(len(insp.tokenizer.encode(CORRUPTED_PROMPT))):\n",
    "        def output_fn(obj):\n",
    "            obj[0,target_token] = obj[0,target_token] + diff2[0,target_token]\n",
    "            return obj\n",
    "        with insp.ctx([set_op.run_params(output_fn=output_fn)]):\n",
    "            corrupted_output = insp.infer(CORRUPTED_PROMPT, chat=False)\n",
    "            if layer_name not in result:\n",
    "                result[layer_name] = []\n",
    "            result[layer_name].append((\n",
    "                corrupted_output.logits[-1][CLS_TRUE].item(),\n",
    "                corrupted_output.logits[-1][CLS_FALSE].item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "96b85bd3-dbcd-4cd9-92d4-a2eaf5b3330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.1 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.2 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.3 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.4 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.5 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.6 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.7 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.8 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.9 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.10 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.11 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.12 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.13 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.14 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.15 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.16 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.17 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.18 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.19 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.20 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.21 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'John']\n",
      "model.layers.22 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.23 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.24 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.25 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.26 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.27 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.28 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.29 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.30 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.31 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.32 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.33 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.34 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n",
      "model.layers.35 ['John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'John', 'Mary']\n"
     ]
    }
   ],
   "source": [
    "for key, value in result.items():\n",
    "    r = [\"John\" if o0 > o1 else \"Mary\" for (o0, o1) in value]\n",
    "    print(key, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ae479-256e-4291-b512-6c3d59f7cbe2",
   "metadata": {},
   "source": [
    "## Patch multiple activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d321d-44fc-4f47-9dc7-83b6facd5e0b",
   "metadata": {},
   "source": [
    "### Single model, 2 different prompts\n",
    "\n",
    "It's possible to replace multiple tokens, except the definitive one, and still change the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ac003a98-a4c3-42c1-adcd-fc1d43413fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.6']\n",
      "(15.875990867614746, 10.416614532470703)\n"
     ]
    }
   ],
   "source": [
    "layer_name = name_pattern.format(layer_idx=6)\n",
    "insp.remove_all()\n",
    "set_op = op.SetOutput()\n",
    "insp.add(set_op, name=layer_name)\n",
    "\n",
    "def output_fn(obj):\n",
    "    for idx in range(len(insp.tokenizer.encode(CORRUPTED_PROMPT))):\n",
    "        if idx in (17,):\n",
    "            continue\n",
    "        obj[0,idx] = clean_state['output'][layer_name][0,idx]\n",
    "    return obj\n",
    "\n",
    "with insp.ctx([set_op.run_params(output_fn=output_fn)]):\n",
    "    corrupted_output = insp.infer(CORRUPTED_PROMPT, chat=False)\n",
    "    print((\n",
    "        corrupted_output.logits[-1][CLS_TRUE].item(),\n",
    "        corrupted_output.logits[-1][CLS_FALSE].item()\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
