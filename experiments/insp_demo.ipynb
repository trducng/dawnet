{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d9ebfec-0bb5-436f-9eb0-982814b10b51",
   "metadata": {},
   "source": [
    "# Demo the model inspection capability\n",
    "\n",
    "- Get the input and output.\n",
    "- Steer from the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01f53d4-9866-47ac-be53-d36d6abcd10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dawnet.inspector import LLMInspector\n",
    "from dawnet import op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5f59b8-7fca-4d96-9b49-0c380ad4649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"When John and Mary went to the store, John gave the bag to\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeec619-57e6-469b-8fdb-0b675d7a952a",
   "metadata": {},
   "source": [
    "### Load the model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bdf19ab-aaa0-4b01-8397-47d6b5e1fc87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9668895bb1424037aa3c569889cf86bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3ForCausalLM(\n",
      "  (model): Qwen3Model(\n",
      "    (embed_tokens): Embedding(151936, 2560)\n",
      "    (layers): ModuleList(\n",
      "      (0-35): 36 x Qwen3DecoderLayer(\n",
      "        (self_attn): Qwen3Attention(\n",
      "          (q_proj): Linear(in_features=2560, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
      "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        )\n",
      "        (mlp): Qwen3MLP(\n",
      "          (gate_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "          (up_proj): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "          (down_proj): Linear(in_features=9728, out_features=2560, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "        (post_attention_layernorm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Qwen3RMSNorm((2560,), eps=1e-06)\n",
      "    (rotary_emb): Qwen3RotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "insp = LLMInspector.from_hf(\"Qwen/Qwen3-4B\")\n",
    "print(insp.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb8098-7acb-45ce-a11c-3d414e0e6d54",
   "metadata": {},
   "source": [
    "### Get the input and output of all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964cf357-adbf-41ab-8b77-64027e26e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.0', 'model.layers.1', 'model.layers.2', 'model.layers.3', 'model.layers.4', 'model.layers.5', 'model.layers.6', 'model.layers.7', 'model.layers.8', 'model.layers.9', 'model.layers.10', 'model.layers.11', 'model.layers.12', 'model.layers.13', 'model.layers.14', 'model.layers.15', 'model.layers.16', 'model.layers.17', 'model.layers.18', 'model.layers.19', 'model.layers.20', 'model.layers.21', 'model.layers.22', 'model.layers.23', 'model.layers.24', 'model.layers.25', 'model.layers.26', 'model.layers.27', 'model.layers.28', 'model.layers.29', 'model.layers.30', 'model.layers.31', 'model.layers.32', 'model.layers.33', 'model.layers.34', 'model.layers.35']\n"
     ]
    }
   ],
   "source": [
    "_ = insp.add(op.GetOutput(), name_regex=r\"model.layers.\\d+$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62ab9b7-1d2c-4937-ace9-ec04c4d44d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with insp.ctx(detach_state=True) as state:\n",
    "  out = insp.infer(text, chat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb86ccfd-82e4-4489-8838-0fd04f58eb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18.8178, 18.4397, 16.6338, 16.2505, 13.9637], device='mps:0',\n",
       "        grad_fn=<TopkBackward0>),\n",
       " tensor([10244,   279,   264,   806, 29405], device='mps:0'),\n",
       " [' Mary', ' the', ' a', ' his', ' Alice'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.topk(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de94e7c-a783-4ee4-985f-3daeb23c5bb9",
   "metadata": {},
   "source": [
    "#### The layer output is stored in `state` variable, and can be accessed as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f4d5ee-080e-428b-ad73-78830eb31f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.layers.0 torch.Size([1, 14, 2560])\n",
      "model.layers.1 torch.Size([1, 14, 2560])\n",
      "model.layers.2 torch.Size([1, 14, 2560])\n",
      "model.layers.3 torch.Size([1, 14, 2560])\n",
      "model.layers.4 torch.Size([1, 14, 2560])\n",
      "model.layers.5 torch.Size([1, 14, 2560])\n",
      "model.layers.6 torch.Size([1, 14, 2560])\n",
      "model.layers.7 torch.Size([1, 14, 2560])\n",
      "model.layers.8 torch.Size([1, 14, 2560])\n",
      "model.layers.9 torch.Size([1, 14, 2560])\n",
      "model.layers.10 torch.Size([1, 14, 2560])\n",
      "model.layers.11 torch.Size([1, 14, 2560])\n",
      "model.layers.12 torch.Size([1, 14, 2560])\n",
      "model.layers.13 torch.Size([1, 14, 2560])\n",
      "model.layers.14 torch.Size([1, 14, 2560])\n",
      "model.layers.15 torch.Size([1, 14, 2560])\n",
      "model.layers.16 torch.Size([1, 14, 2560])\n",
      "model.layers.17 torch.Size([1, 14, 2560])\n",
      "model.layers.18 torch.Size([1, 14, 2560])\n",
      "model.layers.19 torch.Size([1, 14, 2560])\n",
      "model.layers.20 torch.Size([1, 14, 2560])\n",
      "model.layers.21 torch.Size([1, 14, 2560])\n",
      "model.layers.22 torch.Size([1, 14, 2560])\n",
      "model.layers.23 torch.Size([1, 14, 2560])\n",
      "model.layers.24 torch.Size([1, 14, 2560])\n",
      "model.layers.25 torch.Size([1, 14, 2560])\n",
      "model.layers.26 torch.Size([1, 14, 2560])\n",
      "model.layers.27 torch.Size([1, 14, 2560])\n",
      "model.layers.28 torch.Size([1, 14, 2560])\n",
      "model.layers.29 torch.Size([1, 14, 2560])\n",
      "model.layers.30 torch.Size([1, 14, 2560])\n",
      "model.layers.31 torch.Size([1, 14, 2560])\n",
      "model.layers.32 torch.Size([1, 14, 2560])\n",
      "model.layers.33 torch.Size([1, 14, 2560])\n",
      "model.layers.34 torch.Size([1, 14, 2560])\n",
      "model.layers.35 torch.Size([1, 14, 2560])\n"
     ]
    }
   ],
   "source": [
    "for key, value in state['output'].items():\n",
    "  print(key, value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1bc36d-d278-43d1-883b-4e1a63701cb3",
   "metadata": {},
   "source": [
    "### Modify the output of a layer\n",
    "\n",
    "For example, we copy the layer 6 of token Mary to layer 6 of the second token John. We would hope that the model will complete with \"John\" rather than \"Mary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2938116a-dae4-4572-84ff-bfb2617b19c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 When\n",
      "1 ĠJohn\n",
      "2 Ġand\n",
      "3 ĠMary\n",
      "4 Ġwent\n",
      "5 Ġto\n",
      "6 Ġthe\n",
      "7 Ġstore\n",
      "8 ,\n",
      "9 ĠJohn\n",
      "10 Ġgave\n",
      "11 Ġthe\n",
      "12 Ġbag\n",
      "13 Ġto\n"
     ]
    }
   ],
   "source": [
    "tokenized = insp.tokenizer.tokenize(text)\n",
    "for idx, tok in enumerate(tokenized):\n",
    "  print(idx, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cbd8bc-a474-42c7-bccc-2faff570f371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to layer ['model.layers.6']\n"
     ]
    }
   ],
   "source": [
    "# Remove previous GetOutput operation\n",
    "insp.remove_all()\n",
    "\n",
    "# Attach a hook\n",
    "set_op = insp.add(op.SetOutput(), name=\"model.layers.6\")\n",
    "def set_callback(obj):\n",
    "  obj[0,9] = obj[0,3]\n",
    "  return obj\n",
    "\n",
    "with insp.ctx([set_op.run_params(output_fn=set_callback)]):   # Attach the callback function\n",
    "  out2 = insp.infer(text, chat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1070d82-bddc-45d9-b47d-d82981c0daaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([19.0902, 18.4072, 16.2737, 15.2673, 14.9571], device='mps:0',\n",
       "        grad_fn=<TopkBackward0>),\n",
       " tensor([ 3757,   279,   264,  7801, 23223], device='mps:0'),\n",
       " [' John', ' the', ' a', ' James', ' Anna'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.topk(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
