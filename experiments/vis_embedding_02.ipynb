{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb518e4-d0c0-47f5-9bb6-634e6fcdb636",
   "metadata": {},
   "source": [
    "# Check embedding cosine similarity between tokens\n",
    "\n",
    "\n",
    "One thing I notice is that the cosine similarity of hidden representation across tokens are usually positive. Very rarely I can find a pair that has negative cosine similarity. This is interesting, since I intuitively expect there will be some positive, some negative. Maybe the cosine similarities are mostly positive right beginning from the embedding layer.\n",
    "\n",
    "Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00531c34-2486-432a-af7a-1f35dda00136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dawnet.inspector import LLMInspector\n",
    "from dawnet.tokens import Tokens\n",
    "from dawnet import op\n",
    "from dawnet.prompts import get_words, Prompt\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d557d5c-1de5-44bf-abe6-803dc67cab6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5435e35e44954130a53c2675acef8e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma3ForConditionalGeneration(\n",
      "  (model): Gemma3Model(\n",
      "    (vision_tower): SiglipVisionModel(\n",
      "      (vision_model): SiglipVisionTransformer(\n",
      "        (embeddings): SiglipVisionEmbeddings(\n",
      "          (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
      "          (position_embedding): Embedding(4096, 1152)\n",
      "        )\n",
      "        (encoder): SiglipEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-26): 27 x SiglipEncoderLayer(\n",
      "              (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "              (self_attn): SiglipAttention(\n",
      "                (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "                (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "                (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "                (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "              )\n",
      "              (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "              (mlp): SiglipMLP(\n",
      "                (activation_fn): PytorchGELUTanh()\n",
      "                (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "                (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (multi_modal_projector): Gemma3MultiModalProjector(\n",
      "      (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "      (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "    )\n",
      "    (language_model): Gemma3TextModel(\n",
      "      (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)\n",
      "      (layers): ModuleList(\n",
      "        (0-33): 34 x Gemma3DecoderLayer(\n",
      "          (self_attn): Gemma3Attention(\n",
      "            (q_proj): Linear(in_features=2560, out_features=2048, bias=False)\n",
      "            (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "            (o_proj): Linear(in_features=2048, out_features=2560, bias=False)\n",
      "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "          )\n",
      "          (mlp): Gemma3MLP(\n",
      "            (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
      "            (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
      "            (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
      "            (act_fn): PytorchGELUTanh()\n",
      "          )\n",
      "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "      (rotary_emb): Gemma3RotaryEmbedding()\n",
      "      (rotary_emb_local): Gemma3RotaryEmbedding()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=262208, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "insp = LLMInspector.from_hf(\"google/gemma-3-4b-it\")\n",
    "print(insp.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05151e2-df24-4c9a-b9f5-5ba719a329c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_layer(insp):\n",
    "  model_id = insp.model_id.lower()\n",
    "  if \"qwen\" in model_id:\n",
    "    return insp.model.model.embed_tokens\n",
    "  if \"olmo\" in model_id:\n",
    "    return insp.model.model.embed_tokens\n",
    "  if \"oss\" in model_id:\n",
    "    return insp.model.model.embed_tokens\n",
    "  if \"gemma\" in model_id:\n",
    "    return insp.model.language_model.embed_tokens\n",
    "\n",
    "embed_layer = get_embedding_layer(insp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c15f022-3b11-4572-b059-733d9c4df64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cosine_similarity(w, target_idx=None, verbose=False):\n",
    "  if target_idx is None:\n",
    "    target_idx = random.randrange(w.shape[0])\n",
    "  if verbose:\n",
    "    print(target_idx, insp.tokenizer.decode(target_idx))\n",
    "  v = w[target_idx]\n",
    "  others = torch.cat([w[:target_idx], w[target_idx+1:]], dim=0)\n",
    "  if verbose:\n",
    "    print(v.shape)\n",
    "    print(others.shape)\n",
    "  dot_product = others @ v.unsqueeze(1)\n",
    "  norm1 = others.norm(p=2, dim=1, keepdim=True)\n",
    "  norm = norm1 * v.norm(p=2)\n",
    "  c = dot_product / norm\n",
    "  non_neg = (c >= 0).sum().cpu().item()\n",
    "  neg = c.shape[0] - non_neg\n",
    "  _min = round(c.min().cpu().item(), 2)\n",
    "  _max = round(c.max().cpu().item(), 2)\n",
    "  _mean = round(c.mean().cpu().item(), 2)\n",
    "  _median = round(c.median().cpu().item(), 2)\n",
    "  _per = round(non_neg / (non_neg + neg), 4)\n",
    "  if verbose:\n",
    "    print(\n",
    "      \"Min:\", _min,\n",
    "      \"Max:\", _max,\n",
    "      \"Mean:\", _mean,\n",
    "      \"Median:\", _median,\n",
    "      \"Non-negative:\", non_neg,\n",
    "      \"Negative:\", neg,\n",
    "      \"Percentage\", _per\n",
    "  )\n",
    "  return c, _min, _max, _mean, _median, non_neg, neg, _per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa6d9cd-8a36-4b0f-9eb7-997174af71cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -0.09 Max: 0.56 Mean: 0.03 Median: 0.03 Non-negative: 239564.38 Negative: 22642.62 Percentage 0.9136\n"
     ]
    }
   ],
   "source": [
    "times = 50\n",
    "t_min, t_max, t_mean, t_median, t_non_neg, t_neg, t_per = 0, 0, 0, 0, 0, 0, 0\n",
    "for _ in range(times):\n",
    "  _, _min, _max, _mean, _median, _non_neg, _neg, _per = random_cosine_similarity(embed_layer.weight)\n",
    "  t_min += _min\n",
    "  t_max += _max\n",
    "  t_mean += _mean\n",
    "  t_median += _median\n",
    "  t_non_neg += _non_neg\n",
    "  t_neg += _neg\n",
    "  t_per += _per\n",
    "\n",
    "print(\n",
    "    \"Min:\", round(t_min / times, 2),\n",
    "    \"Max:\", round(t_max / times, 2),\n",
    "    \"Mean:\", round(t_mean / times, 2),\n",
    "    \"Median:\", round(t_median / times, 2),\n",
    "    \"Non-negative:\", round(t_non_neg / times,2),\n",
    "    \"Negative:\", round(t_neg / times, 2),\n",
    "    \"Percentage\", round(t_per / times, 4)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "977219aa-8fb5-46b1-9a28-a09cc1f63781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of positive cosine simlarity for random embedding layer 0.501\n"
     ]
    }
   ],
   "source": [
    "ran_embed = nn.Embedding(\n",
    "  num_embeddings=embed_layer.weight.shape[0],\n",
    "  embedding_dim=embed_layer.weight.shape[1],\n",
    ")\n",
    "\n",
    "_, _min, _max, _mean, _median, _non_neg, _neg, _per = random_cosine_similarity(ran_embed.weight)\n",
    "print(\"% of positive cosine simlarity for random embedding layer\", _per)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6ebe8-06f8-40ba-a5bd-6e3510aae307",
   "metadata": {},
   "source": [
    "### Zoom in closer into tokens that have negative similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8aa98ff-1a79-4ee8-ab99-0d370e988a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73048 µ\n",
      "torch.Size([2560])\n",
      "torch.Size([151935, 2560])\n",
      "Min: -0.11 Max: 0.82 Mean: 0.05 Median: 0.05 Non-negative: 148898 Negative: 3037 Percentage 0.98\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  45,  46,  47,  49,  50,  51,  53,  54,  55,  56,  58,  59,\n",
      "         60,  61,  62,  64,  65,  66,  67,  68,  69,  71,  72,  73,  74,  75,\n",
      "         77,  78,  79,  81,  82,  83,  86,  87,  88,  90,  91,  92, 120, 149,\n",
      "        151, 170, 197, 198, 201, 220, 222, 230, 231, 233, 234, 245, 253, 254,\n",
      "        256, 257], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "cos, _,_,_,_,_,_,_ = random_cosine_similarity(embed_layer.weight, verbose=True)\n",
    "_temp = (cos < 0).nonzero()\n",
    "print(_temp[:100,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89f1e06-c5c7-4e5b-8c79-52148fe38711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLNOPRSTVWXY[\\\\]^_abcdefhijklnoprstwxy{|}����\\t\\n\\r ���'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insp.tokenizer.decode(_temp[:93,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2010b8f5-b2d5-4653-8bea-4af476047c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192 \u0004\n",
      "Min: -0.29 Max: 0.6 Mean: 0.04 Non-negative: 136608 Negative: 64479\n"
     ]
    }
   ],
   "source": [
    "_ = random_cosine_similarity(embed_layer.weight, target_idx=192)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
