{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05991d46-5c04-485a-975e-132cd8061719",
   "metadata": {},
   "source": [
    "# SAE train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5965802-ec8a-4232-9426-9502f72f24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import lightning as L\n",
    "import json\n",
    "from pathlib import Path\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c53b9-a6b3-4d91-93f5-12381ae1067d",
   "metadata": {},
   "source": [
    "## Data and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "076eea8b-2e23-404a-a3be-b8028911ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntermediateStateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths):\n",
    "        from pathlib import Path\n",
    "\n",
    "        self.path_names = list(sorted(paths))\n",
    "        self.nps = [np.load(each, mmap_mode=\"r\") for each in self.path_names]\n",
    "        self.sizes = []\n",
    "        count = 0\n",
    "        for each in self.nps:\n",
    "            self.sizes.append(count)\n",
    "            count += each.shape[0]\n",
    "        self.sizes = np.array(self.sizes)\n",
    "        self.total_size = count\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "    def _get(self, idx):\n",
    "        bucket_idx = (idx >= self.sizes).sum() - 1\n",
    "        remainder = idx - self.sizes[bucket_idx]\n",
    "        return self.nps[bucket_idx][remainder]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            if idx < 0:\n",
    "                idx = len(self) + idx\n",
    "            return self._get(idx)\n",
    "        elif isinstance(idx, slice):\n",
    "            start = idx.start or 0\n",
    "            stop = idx.stop or len(self)\n",
    "            step = idx.step or 1\n",
    "            result = []\n",
    "            for iidx in range(start, stop, step):\n",
    "                result.append(self._get(iidx))\n",
    "            return np.stack(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882a5bc8-29ae-4d3f-9605-6cca234a1e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6857125 128078235 2923962\n"
     ]
    }
   ],
   "source": [
    "paths = list(sorted(Path(\"/data/mech/data/layers/transformer.h.10\").glob(\"*.npy\")))\n",
    "train_paths = paths[:-10]\n",
    "test_paths = paths[-10:-3]\n",
    "val_paths = paths[-3:]\n",
    "\n",
    "train_dataset = IntermediateStateDataset(train_paths)\n",
    "test_dataset = IntermediateStateDataset(test_paths)\n",
    "val_dataset = IntermediateStateDataset(val_paths)\n",
    "\n",
    "print(len(test_dataset), len(train_dataset), len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb4cf48-e06e-48f8-93e2-3cedd4668734",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_callback = ModelCheckpoint(train_time_interval=timedelta(minutes=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c365c-a13a-458b-beed-ecfa721dadf0",
   "metadata": {},
   "source": [
    "## Force SAE to be sparsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21ab73-b34d-4673-aee1-4e630e036e8c",
   "metadata": {},
   "source": [
    "### A dumb SAE\n",
    "\n",
    "This SAE even uses Sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463df1b8-4d4e-4709-84b6-fbe7053b892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAEDumb(L.LightningModule):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.encoder(x)\n",
    "        x = self.decoder(hidden)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        output = self.forward(batch[0])\n",
    "        loss = self.loss(batch[0], output)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    def sanity_check(self, input_):\n",
    "        with torch.no_grad():\n",
    "            output = self(to_test)\n",
    "        return 1 - torch.mean((saedumb_output - to_test) ** 2) / to_test.var()\n",
    "\n",
    "    def act(self, input_):\n",
    "        with torch.no_grad():\n",
    "            act = self.encoder(input_)\n",
    "        return input_\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def check(self, to_test):\n",
    "        with torch.no_grad():\n",
    "            sae_output = self(to_test)\n",
    "            with torch.no_grad():\n",
    "                act = self.encode(to_test)\n",
    "            print(\"Reconstruction capability:\", 1 - torch.mean((sae_output - to_test) ** 2) / to_test.var())\n",
    "            print(\"Number of activated:\", (act > 0).sum())\n",
    "            print(\"Percentage of activated:\", (act > 0).sum() / act.numel())\n",
    "\n",
    "    def active_feature_statistics(self, dataloader):\n",
    "        self.cuda()\n",
    "        with torch.no_grad():\n",
    "            total = torch.zeros(self.hparams.hidden_size).cuda()\n",
    "            for batch in dataloader:\n",
    "                act = self.encode(batch.cuda())\n",
    "                total += (act > 0).sum(dim=0)\n",
    "        self.cpu()\n",
    "        total = total.detach().cpu().numpy().squeeze()\n",
    "        print(\"Quantiles:\", np.quantile(total, [0.01, 0.02, 0.05, 0.1, 0.5, 0.9, 0.95, 0.98, 0.99]))\n",
    "        print(\"Mean:\", np.mean(total))\n",
    "        return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9978e-9a64-49d8-8f4a-b6e78de02492",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762b6bc0-d1db-432a-a585-62f1c68ee5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "saedumb = SAEDumb(768, 3000)\n",
    "trainer = L.Trainer(accelerator=\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eead3f9-6d58-4b4a-bdb7-56086aea6300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_900403/4042388959.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  saedumb.load_state_dict(torch.load(\"/data/mech/data/ckpts/saedumb.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saedumb = SAEDumb(768, 3000)\n",
    "saedumb.load_state_dict(torch.load(\"/data/mech/data/ckpts/saedumb.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7dcd01-981d-496e-b5e4-f8b82bd17d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(saedumb, train_dataloaders=[torch.utils.data.DataLoader(train_dataset, batch_size=256)], val_dataloaders=[torch.utils.data.DataLoader(val_dataset, batch_size=513)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be62a872-35c0-4120-9d94-b41127269c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(saedumb.state_dict(), \"/data/mech/data/ckpts/saedumb.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e78abe-4641-44ec-a37b-e8b78486e9f3",
   "metadata": {},
   "source": [
    "### Remove the final sigmoid activation\n",
    "\n",
    "| xx | Total features | % Activated |\n",
    "| -- | -------------- | ----------- |\n",
    "| 32x | 24576 | 0.1105 |\n",
    "\n",
    "Even though there are only 11% of the activation are activated. It seems that this number is still quite high, as there are around 2000 activated features. On the other hand, the work from Anthorpic only has around 14, 15 activated features. We should induce ways to enforce sparsity.\n",
    "\n",
    "Also, the number of activated features seems to be relatively constant. Previously when I try a dumb experiment with 8888 features, around 3000 features are always activated. Should do more experiment on xx.\n",
    "\n",
    "- [ ] Test with 1x, 2x, 4x, 8x, 16x, 32x, 64x, 128x, 256x\n",
    "- [x] Add L1 norm to induce sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90ff4e5-461c-4e92-850c-8fa85f1d8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(SAEDumb):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__(input_size, hidden_size)\n",
    "        self.encoder = nn.Linear(in_features=input_size, out_features=hidden_size, bias=True)\n",
    "        self.thresh = nn.Parameter(torch.zeros(hidden_size), requires_grad=True)\n",
    "        self.decoder = nn.Linear(in_features=hidden_size, out_features=input_size, bias=True)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def encode(self, x):\n",
    "        y = self.encoder(x)\n",
    "        mask = (y > self.thresh)\n",
    "        y = mask * nn.functional.relu(y)\n",
    "        return y\n",
    "\n",
    "    def decode(self, x):\n",
    "        y = self.decoder(x)\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.encode(x)\n",
    "        y = self.decode(y)\n",
    "        return y\n",
    "\n",
    "    def act(self, input_):\n",
    "        with torch.no_grad():\n",
    "            act = self.encode(input_)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522493c1-fb3a-4ce4-be29-39f7c652646c",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0cd018-4d32-4072-b843-138fc0e9dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "sae = SAE(768, 24576)\n",
    "trainer = L.Trainer(accelerator=\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe4505-2255-4a9a-b458-d0899b14a5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type    | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder      | Linear  | 18.9 M | train\n",
      "1 | decoder      | Linear  | 18.9 M | train\n",
      "2 | loss         | MSELoss | 0      | train\n",
      "  | other params | n/a     | 24.6 K | n/a  \n",
      "-------------------------------------------------\n",
      "37.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.8 M    Total params\n",
      "151.195   Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:223: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(sae, train_dataloaders=[torch.utils.data.DataLoader(train_dataset, batch_size=256)], val_dataloaders=[torch.utils.data.DataLoader(val_dataset, batch_size=512)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e7b058-4a63-4ec6-8002-b119e0347d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sae.state_dict(), \"/data/mech/data/ckpts/sae.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "995e684a-071f-4ffc-a3c8-898d15582846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction capability: tensor(0.9999)\n",
      "Number of activated: tensor(2715)\n",
      "Percentage of activated: tensor(0.1105)\n"
     ]
    }
   ],
   "source": [
    "to_test = torch.Tensor(test_dataset[23]).unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    # saedumb_output = saedumb(to_test)\n",
    "    # print(1 - torch.mean((saedumb_output - to_test) ** 2) / to_test.var())\n",
    "    sae_output = sae(to_test)\n",
    "    with torch.no_grad():\n",
    "        act = sae.encode(to_test)\n",
    "    print(\"Reconstruction capability:\", 1 - torch.mean((sae_output - to_test) ** 2) / to_test.var())\n",
    "    print(\"Number of activated:\", (act > 0).sum())\n",
    "    print(\"Percentage of activated:\", (act > 0).sum() / act.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05abb421-d4de-47c2-b449-00a42edc1d02",
   "metadata": {},
   "source": [
    "### L1 norm\n",
    "\n",
    "Failed experiment:\n",
    "- lambda = 1e-3. The end result is the final activations are pushed toward 0.\n",
    "- lambda = 1e-5. It's better with 688 activated features.\n",
    "\n",
    "Todo:\n",
    "\n",
    "- [x] Fix the norm implementation\n",
    "- [x] Test lambda 1e-5. --> Does help a lot\n",
    "- [x] Test lambda 1e-4.\n",
    "- [x] Retry with lambda 1e-4. Because there are a lot of dead weights. We would want to confirm if those dead weights are universal -> Similar statistics.\n",
    "- [ ] Retest with lambda 1e-5.\n",
    "- [ ] Test with 64x.\n",
    "- [ ] Revive dead weights for every 100000 inactive instances.\n",
    "\n",
    "**Test lambda 1e-5**: Does reduce the number of activated features from 2000 to 600. There still a long way to go to reduce the number of features to 100.\n",
    "\n",
    "#### Thought\n",
    "\n",
    "- We need to keep track of inactive features. The reason might purely because of unlucky initialization. Approaches:\n",
    "  - Reset the weights of unlucky features.\n",
    "  - Use different activation features so that a feature has much lower chance of being dead.\n",
    "\n",
    "A randomly-initialized weights show that:\n",
    "\n",
    "- Around 50% of the features are 0 for a test instance\n",
    "- 0 features are always 0 for all test data in dataset\n",
    "---> So it seems \n",
    "\n",
    "#### Retry with lambda 1e-4\n",
    "\n",
    "The statistics is similar:\n",
    "\n",
    "- 10099 dead features vs 9975 dead features.\n",
    "- Quantiles:\n",
    "  - 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3000000e+01 4.4500000e+02 6.8000540e+06 6.8324995e+06 6.8368465e+06\n",
    "  - 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.40000000e+01 6.79720100e+06 6.82264975e+06 6.82933450e+06 6.83185225e+06\n",
    "\n",
    "The mean is different: 451596.62 vs 882056.44. The 2nd run have more activated features than the 1st run. Maybe if we keep the training running, the feature will just keep becoming dead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5694438-a8fb-460b-9c9e-35454a3e7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAEWithL1(SAE):\n",
    "    def __init__(self, input_size, hidden_size, lmd, dead_feature_refresh_rate=2000):\n",
    "        super().__init__(input_size, hidden_size)\n",
    "        self.lmd = lmd\n",
    "        self.save_hyperparameters()\n",
    "        self.register_buffer(\"counter\", torch.zeros(hidden_size))\n",
    "        self.dfrr = dead_feature_refresh_rate\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        act, output = self.forward(batch[0])\n",
    "        if batch_nb % 20 == 0:\n",
    "            # sample every 20 iterations\n",
    "            self.counter += act.sum(dim=0)\n",
    "        loss = self.loss(batch[0], output)\n",
    "        reg = torch.norm(act, 1)\n",
    "        total_loss = loss + self.lmd * reg\n",
    "        self.log(\"loss\", loss, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
    "        self.log(\"reg\", reg, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
    "        self.log(\"total_loss\", total_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        if batch_idx % self.dfrr == 0 and batch_idx >= self.dfrr:\n",
    "            self.revive_dead_features()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        y = self.decode(z)\n",
    "        return z, y\n",
    "\n",
    "    def check(self, to_test):\n",
    "        with torch.no_grad():\n",
    "            sae_output = self(to_test)[-1]\n",
    "            with torch.no_grad():\n",
    "                act = self.encode(to_test)\n",
    "            print(\"Reconstruction capability:\", 1 - torch.mean((sae_output - to_test) ** 2) / to_test.var())\n",
    "            print(\"Number of activated:\", (act > 0).sum())\n",
    "            print(\"Percentage of activated:\", (act > 0).sum() / act.shape[1])\n",
    "\n",
    "    def revive_dead_features(self):\n",
    "        \"\"\"Randomly changing the weights to avoid dead features\"\"\"\n",
    "        with torch.no_grad():\n",
    "            idxs = (self.counter == 0).nonzero()\n",
    "            nn.init.kaiming_uniform_(self.encoder.weight[idxs], a=math.sqrt(5))\n",
    "            self.counter = torch.zeros(self.hparams.hidden_size, device=self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d5960a-c643-4c48-a1a4-297c01ba78c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Experiment with lambda 1e-4\n",
    "\n",
    "Some features are always active. Some features never. It seems the problem comes from weight initialization, such that some features become inactive almost always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "577c1095-54f4-4e43-9938-471a23f46358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:72: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:68: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type    | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder      | Linear  | 18.9 M | train\n",
      "1 | decoder      | Linear  | 18.9 M | train\n",
      "2 | loss         | MSELoss | 0      | train\n",
      "  | other params | n/a     | 24.6 K | n/a  \n",
      "-------------------------------------------------\n",
      "37.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.8 M    Total params\n",
      "151.195   Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5227dd06b65940c0ab6ff7e6be06b972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/miniconda3/envs/dawnet/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:223: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:269\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m--> 269\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_train_batch_end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_batch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_output, batch, batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:218\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/callbacks/progress/tqdm_progress.py:279\u001b[0m, in \u001b[0;36mTQDMProgressBar.on_train_batch_end\u001b[0;34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001b[0m\n\u001b[1;32m    278\u001b[0m _update_n(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_progress_bar, n)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/callbacks/progress/progress_bar.py:198\u001b[0m, in \u001b[0;36mProgressBar.get_metrics\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    197\u001b[0m standard_metrics \u001b[38;5;241m=\u001b[39m get_standard_metrics(trainer)\n\u001b[0;32m--> 198\u001b[0m pbar_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_metrics\u001b[49m\n\u001b[1;32m    199\u001b[0m duplicates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(standard_metrics\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m&\u001b[39m pbar_metrics\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1635\u001b[0m, in \u001b[0;36mTrainer.progress_bar_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The metrics sent to the progress bar.\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \n\u001b[1;32m   1631\u001b[0m \u001b[38;5;124;03mThis includes metrics logged via :meth:`~lightning.pytorch.core.LightningModule.log` with the\u001b[39;00m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;124;03m:paramref:`~lightning.pytorch.core.LightningModule.log.prog_bar` argument set.\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m \n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logger_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_bar_metrics\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:253\u001b[0m, in \u001b[0;36m_LoggerConnector.progress_bar_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results:\n\u001b[0;32m--> 253\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_bar_metrics\u001b[38;5;241m.\u001b[39mupdate(metrics)\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:234\u001b[0m, in \u001b[0;36m_LoggerConnector.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:490\u001b[0m, in \u001b[0;36m_ResultCollection.metrics\u001b[0;34m(self, on_step)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result_metric\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mprog_bar:\n\u001b[0;32m--> 490\u001b[0m         metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpbar\u001b[39m\u001b[38;5;124m\"\u001b[39m][forked_name] \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_tensors_to_scalars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py:136\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_item\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:64\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, dtype):  \u001b[38;5;66;03m# single element\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, dtype) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data):  \u001b[38;5;66;03m# 1d homogeneous list\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py:134\u001b[0m, in \u001b[0;36mconvert_tensors_to_scalars.<locals>.to_item\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metric `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` does not contain a single element, thus it cannot be converted to a scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(original_weights, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/mech/data/ckpts/temporaries/lambda_1e-4_beginning_run2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[ckpt_callback])\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaewithl1_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dawnet/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "saewithl1_2 = SAEWithL1(768, 24576, 1e-4)\n",
    "# original_weights = saewithl1_2.state_dict()\n",
    "# torch.save(original_weights, \"/data/mech/data/ckpts/temporaries/lambda_1e-4_beginning_run2.pth\")\n",
    "trainer = L.Trainer(accelerator=\"gpu\", callbacks=[ckpt_callback])\n",
    "trainer.fit(\n",
    "    saewithl1_2,\n",
    "    train_dataloaders=[torch.utils.data.DataLoader(train_dataset, batch_size=256)],\n",
    "    val_dataloaders=[torch.utils.data.DataLoader(val_dataset, batch_size=512)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99380e9-4832-4013-9d40-218e1f0a86e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction capability: tensor(0.9997)\n",
      "Number of activated: tensor(3082)\n",
      "Percentage of activated: tensor(0.1254)\n"
     ]
    }
   ],
   "source": [
    "saewithl1_2.check(torch.Tensor(test_dataset[0]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e8fbd-e3fa-4df1-b8b2-ab538133d185",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Examine the weights\n",
    "\n",
    "There are indeed a lot of dead features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20d84da1-71c9-4b68-a1e8-c85f55c97dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.Tensor(test_dataset[0]).unsqueeze(dim=0)\n",
    "with torch.no_grad():\n",
    "    act = saewithl1_2.encode(sample)\n",
    "    act = act.cpu().numpy()\n",
    "\n",
    "print(act[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25991e07-d55f-4968-8e3c-dfe2e7575771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 24576\n",
      "tensor(-0.0057, grad_fn=<SumBackward0>)\n",
      "tensor(-2.2566e-10, grad_fn=<SumBackward0>)\n",
      "tensor(-1.1012e-22, grad_fn=<SumBackward0>)\n",
      "tensor(-0.0673, grad_fn=<SumBackward0>)\n",
      "tensor(-0.0022, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoder = saewithl1_2.encoder\n",
    "print(encoder.in_features, encoder.out_features)\n",
    "print(encoder.weight[0].sum())\n",
    "print(encoder.weight[1].sum())\n",
    "print(encoder.weight[2].sum())\n",
    "print(encoder.weight[3].sum())\n",
    "print(encoder.weight[1923].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b91d1f-292a-43ed-96ed-e9068ae95378",
   "metadata": {},
   "source": [
    "#### Train with reviving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e6b8b-9a2e-46b7-934c-931419c41754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type    | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder      | Linear  | 18.9 M | train\n",
      "1 | decoder      | Linear  | 18.9 M | train\n",
      "2 | loss         | MSELoss | 0      | train\n",
      "  | other params | n/a     | 24.6 K | n/a  \n",
      "-------------------------------------------------\n",
      "37.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.8 M    Total params\n",
      "151.195   Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4aa9585bc64312bff4bf557da0ff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                       | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saewithl1 = SAEWithL1(768, 24576, 1e-4, dead_feature_refresh_rate=5000)\n",
    "# original_weights = saewithl1_2.state_dict()\n",
    "# torch.save(original_weights, \"/data/mech/data/ckpts/temporaries/lambda_1e-4_beginning_run2.pth\")\n",
    "trainer = L.Trainer(accelerator=\"gpu\", callbacks=[ckpt_callback])\n",
    "trainer.fit(\n",
    "    saewithl1,\n",
    "    train_dataloaders=[torch.utils.data.DataLoader(train_dataset, batch_size=256)],\n",
    "    val_dataloaders=[torch.utils.data.DataLoader(val_dataset, batch_size=512)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55f704-303e-433b-9bfb-d8c011f29d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
