{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2eb2c2-6def-48ed-97d9-a2ad417ec619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2056265-574d-44da-bc0d-ad7a16427442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61ab07ef32948a2b4c6a8f483368f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
      "W0923 00:47:30.683000 48078 torch/distributed/elastic/multiprocessing/redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2643edec5b4ae3a3cef5d39b46964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7012f15ac2684c679d6320ac95352439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8af6c530c8a4a77a535e8911d3105e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee9edf1f40f4cd5b532bb2d0863957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2f1118de084e6992a5efa444337c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc2209e253d4246878b2e1f3fbdb5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-4b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "397239c2-993c-4ed3-b5e2-a58b432ee928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a03631156684a299b9c817649d89312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af52bb53f30641159726611799e706e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e790ae21bc44db48fe1522a4b55e720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfed8e6d15084589ae3afe204985b567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98efc42941a04d3cbceb693d6b7b65d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-4b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0493056b-55fb-4f19-88e7-df14499ad4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma3ForConditionalGeneration(\n",
      "  (model): Gemma3Model(\n",
      "    (vision_tower): SiglipVisionModel(\n",
      "      (vision_model): SiglipVisionTransformer(\n",
      "        (embeddings): SiglipVisionEmbeddings(\n",
      "          (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
      "          (position_embedding): Embedding(4096, 1152)\n",
      "        )\n",
      "        (encoder): SiglipEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-26): 27 x SiglipEncoderLayer(\n",
      "              (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "              (self_attn): SiglipAttention(\n",
      "                (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "                (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "                (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "                (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
      "              )\n",
      "              (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "              (mlp): SiglipMLP(\n",
      "                (activation_fn): PytorchGELUTanh()\n",
      "                (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
      "                (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (multi_modal_projector): Gemma3MultiModalProjector(\n",
      "      (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
      "      (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "    )\n",
      "    (language_model): Gemma3TextModel(\n",
      "      (embed_tokens): Gemma3TextScaledWordEmbedding(262208, 2560, padding_idx=0)\n",
      "      (layers): ModuleList(\n",
      "        (0-33): 34 x Gemma3DecoderLayer(\n",
      "          (self_attn): Gemma3Attention(\n",
      "            (q_proj): Linear(in_features=2560, out_features=2048, bias=False)\n",
      "            (k_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "            (o_proj): Linear(in_features=2048, out_features=2560, bias=False)\n",
      "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
      "          )\n",
      "          (mlp): Gemma3MLP(\n",
      "            (gate_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
      "            (up_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
      "            (down_proj): Linear(in_features=10240, out_features=2560, bias=False)\n",
      "            (act_fn): PytorchGELUTanh()\n",
      "          )\n",
      "          (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "          (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "          (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "          (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
      "      (rotary_emb): Gemma3RotaryEmbedding()\n",
      "      (rotary_emb_local): Gemma3RotaryEmbedding()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=262208, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7fff8-ee33-4df5-8854-5463a61323ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0e48da-6d65-4f8d-9709-b79cf66bf0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3497fdacfc4608bbb40527f59be98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c13b699dadf4cac8117353bf6cf9b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/testmini-00000-of-00001-725687bf7a1(…):   0%|          | 0.00/142M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a29a31da634a5d8563f16fa66793b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00002-6b81bd7f7e2065e(…):   0%|          | 0.00/358M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3582e186525f4e718edc1f3ec60b456b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00001-of-00002-6a611c71596db30(…):   0%|          | 0.00/386M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eea6d2b5934b03bea81249c1a27322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating testmini split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dcfcae2c1b47499ed8579c36324ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5141 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"AI4Math/MathVista\",split=\"testmini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b711e1-f610-4913-bb6f-830e26fa55d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff2dd9fe1404db59b3151acb4ecad74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566\n"
     ]
    }
   ],
   "source": [
    "def is_numeric_answer(example):\n",
    "  try:\n",
    "    float(example[\"answer\"])\n",
    "    return True\n",
    "  except:\n",
    "    return False\n",
    "\n",
    "dataset = dataset.filter(is_numeric_answer)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eba176d4-07ea-4233-864a-228c655cce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0857733f5f604f4a9207ffd15b13d772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0502708b0b344c3b2ce7c9e2d15f15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def resize_images(example):\n",
    "    image = example[\"decoded_image\"]\n",
    "    image = image.resize((512,512))\n",
    "    example[\"decoded_image\"] = image\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(resize_images)\n",
    "def convert_to_rgb(example):\n",
    "    image = example[\"decoded_image\"]\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "    example[\"decoded_image\"] = image\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(convert_to_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fbe221d-951d-4951-9254-614e50fd6fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fe533201834ccd9ecdeafd460dcbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the delimiter variables for clarity and easy modification\n",
    "REASONING_START = \"<REASONING>\"\n",
    "REASONING_END = \"</REASONING>\"\n",
    "SOLUTION_START = \"<SOLUTION>\"\n",
    "SOLUTION_END = \"</SOLUTION>\"\n",
    "\n",
    "def make_conversation(example):\n",
    "    # Define placeholder constants if they are not defined globally\n",
    "\n",
    "    # The user's text prompt\n",
    "    text_content = (\n",
    "        f\"{example['question']}, provide your reasoning between {REASONING_START} and {REASONING_END} \"\n",
    "        f\"and then your final answer between {SOLUTION_START} and (put a float here) {SOLUTION_END}\"\n",
    "    )\n",
    "\n",
    "    # Construct the prompt in the desired multi-modal format\n",
    "    prompt = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},  # Placeholder for the image\n",
    "                {\"type\": \"text\", \"text\": text_content},  # The text part of the prompt\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # The actual image data is kept separate for the processor\n",
    "    return {\"prompt\": prompt, \"image\": example[\"decoded_image\"], \"answer\": example[\"answer\"]}\n",
    "\n",
    "train_dataset = dataset.map(make_conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca87782-7e90-41c6-b14e-59f5644346d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11208ccf-65b3-4976-b2ae-e81daa215c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "644c5fca-2aee-4080-96d3-71080ced5b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"decoded_image\", \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a82d2e2-b91b-47ca-bfff-9eb9692cf1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pid': '1',\n",
       " 'question': \"When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?\",\n",
       " 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512>,\n",
       " 'choices': None,\n",
       " 'unit': None,\n",
       " 'precision': 1.0,\n",
       " 'answer': '1.2',\n",
       " 'question_type': 'free_form',\n",
       " 'answer_type': 'float',\n",
       " 'metadata': {'category': 'math-targeted-vqa',\n",
       "  'context': 'scientific figure',\n",
       "  'grade': 'college',\n",
       "  'img_height': 720,\n",
       "  'img_width': 1514,\n",
       "  'language': 'english',\n",
       "  'skills': ['scientific reasoning'],\n",
       "  'source': 'SciBench',\n",
       "  'split': 'testmini',\n",
       "  'task': 'textbook question answering'},\n",
       " 'query': \"Hint: Please answer the question requiring a floating-point number with one decimal place and provide the final value, e.g., 1.2, 1.3, 1.4, at the end.\\nQuestion: When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?\",\n",
       " 'prompt': [{'content': [{'text': None, 'type': 'image'},\n",
       "    {'text': \"When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?, provide your reasoning between <REASONING> and </REASONING> and then your final answer between <SOLUTION> and (put a float here) </SOLUTION>\",\n",
       "     'type': 'text'}],\n",
       "   'role': 'user'}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "218f906f-efd2-46ae-8f80-3c692caacfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e5820ef3764b468274a962264849ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/566 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    lambda example: {\n",
    "        \"prompt\": tokenizer.apply_chat_template(\n",
    "            example[\"prompt\"],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b8c7804-3db5-4748-bb7b-566a19fbdd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pid': '1',\n",
       " 'question': \"When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?\",\n",
       " 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512>,\n",
       " 'choices': None,\n",
       " 'unit': None,\n",
       " 'precision': 1.0,\n",
       " 'answer': '1.2',\n",
       " 'question_type': 'free_form',\n",
       " 'answer_type': 'float',\n",
       " 'metadata': {'category': 'math-targeted-vqa',\n",
       "  'context': 'scientific figure',\n",
       "  'grade': 'college',\n",
       "  'img_height': 720,\n",
       "  'img_width': 1514,\n",
       "  'language': 'english',\n",
       "  'skills': ['scientific reasoning'],\n",
       "  'source': 'SciBench',\n",
       "  'split': 'testmini',\n",
       "  'task': 'textbook question answering'},\n",
       " 'query': \"Hint: Please answer the question requiring a floating-point number with one decimal place and provide the final value, e.g., 1.2, 1.3, 1.4, at the end.\\nQuestion: When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?\",\n",
       " 'prompt': \"<bos><start_of_turn>user\\n<start_of_image>When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?, provide your reasoning between <REASONING> and </REASONING> and then your final answer between <SOLUTION> and (put a float here) </SOLUTION><end_of_turn>\\n\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd2e180-0050-4d5e-bc63-67809b2f65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-unsloth\n",
    "# Reward functions\n",
    "def formatting_reward_func(completions,**kwargs):\n",
    "    import re\n",
    "    thinking_pattern = f'{REASONING_START}(.*?){REASONING_END}'\n",
    "    answer_pattern = f'{SOLUTION_START}(.*?){SOLUTION_END}'\n",
    "\n",
    "    scores=[]\n",
    "    for completion in completions :\n",
    "      score=0\n",
    "      thinking_matches = re.findall(thinking_pattern, completion, re.DOTALL)\n",
    "      answer_matches = re.findall(answer_pattern, completion, re.DOTALL)\n",
    "      if len(thinking_matches) == 1 :   # if there are thinking\n",
    "        score +=1.0\n",
    "      if len(answer_matches) == 1 :    # if there are answer\n",
    "        score +=1.0\n",
    "      scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    import re   # if answer correctly\n",
    "\n",
    "    answer_pattern = f'{SOLUTION_START}(.*?){SOLUTION_END}'\n",
    "\n",
    "    responses = [re.findall(answer_pattern, completion, re.DOTALL) for completion in completions]\n",
    "    q = prompts[0]\n",
    "\n",
    "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:{completions[0]}\")\n",
    "    return [2.0 if len(r)==1 and a == r[0].replace('\\n','') else 0.0 for r, a in zip(responses, answer)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "522b056a-c024-442c-86c5-e94552b58c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<bos><start_of_turn>user\\n<start_of_image>When a spring does work on an object, we cannot find the work by simply multiplying the spring force by the object's displacement. The reason is that there is no one value for the force-it changes. However, we can split the displacement up into an infinite number of tiny parts and then approximate the force in each as being constant. Integration sums the work done in all those parts. Here we use the generic result of the integration.\\r\\n\\r\\nIn Figure, a cumin canister of mass $m=0.40 \\\\mathrm{~kg}$ slides across a horizontal frictionless counter with speed $v=0.50 \\\\mathrm{~m} / \\\\mathrm{s}$. It then runs into and compresses a spring of spring constant $k=750 \\\\mathrm{~N} / \\\\mathrm{m}$. When the canister is momentarily stopped by the spring, by what distance $d$ is the spring compressed?, provide your reasoning between <REASONING> and </REASONING> and then your final answer between <SOLUTION> and (put a float here) </SOLUTION><end_of_turn>\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"prompt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f80083-6420-4760-b673-0985ab1c885c",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30679ce6-da3b-49db-98c9-3d5abebfe662",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 16,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 16,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860c516c-d696-4215-86ff-aef610538c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dawnet.experimentals.qwen3.model import Qwen3Model, Qwen3Tokenizer, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3deeac-c985-45a0-9253-b29235a614f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Qwen3Model.default_config(\"4B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77b3a565-9c44-427c-990c-06c3cda40cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 151936,\n",
       " 'context_length': 40960,\n",
       " 'emb_dim': 2560,\n",
       " 'n_heads': 32,\n",
       " 'n_layers': 36,\n",
       " 'hidden_dim': 9728,\n",
       " 'head_dim': 128,\n",
       " 'qk_norm': True,\n",
       " 'n_kv_groups': 8,\n",
       " 'rope_base': 1000000.0,\n",
       " 'dtype': 'bf16'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d6413b-8a08-4299-9086-57fb743cc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qwen3Model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e29f00d-516d-40e2-b1d7-42084b7f8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/Users/john/.cache/huggingface/hub/models--Qwen--Qwen3-4B/snapshots/1cfa9a7208912126459214e8b04321603b3df60c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58825905-61f1-4a16-8945-e67738e203fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65cca691-19fe-4f19-a8a3-8efdd01ee5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(prefix, \"model.safetensors.index.json\").open(\"r\") as fi:\n",
    "    data = json.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4742b3c-9ba4-4752-bb03-3d9945548492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 151936,\n",
       " 'context_length': 40960,\n",
       " 'emb_dim': 2560,\n",
       " 'n_heads': 32,\n",
       " 'n_layers': 36,\n",
       " 'hidden_dim': 9728,\n",
       " 'head_dim': 128,\n",
       " 'qk_norm': True,\n",
       " 'n_kv_groups': 8,\n",
       " 'rope_base': 1000000.0,\n",
       " 'dtype': torch.bfloat16}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b9fe7-3c4f-41fd-b2cd-77900c54c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"architectures\": [\n",
    "    \"Qwen3ForCausalLM\"\n",
    "  ],\n",
    "  \"attention_bias\": false,\n",
    "  \"attention_dropout\": 0.0,\n",
    "  \"bos_token_id\": 151643,\n",
    "  \"eos_token_id\": 151645,\n",
    "  \"head_dim\": 128,\n",
    "  \"hidden_act\": \"silu\",\n",
    "  \"hidden_size\": 2560,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 9728,\n",
    "  \"max_position_embeddings\": 40960,\n",
    "  \"max_window_layers\": 36,\n",
    "  \"model_type\": \"qwen3\",\n",
    "  \"num_attention_heads\": 32,\n",
    "  \"num_hidden_layers\": 36,\n",
    "  \"num_key_value_heads\": 8,\n",
    "  \"rms_norm_eps\": 1e-06,\n",
    "  \"rope_scaling\": null,\n",
    "  \"rope_theta\": 1000000,\n",
    "  \"sliding_window\": null,\n",
    "  \"tie_word_embeddings\": true,\n",
    "  \"torch_dtype\": \"bfloat16\",\n",
    "  \"transformers_version\": \"4.51.0\",\n",
    "  \"use_cache\": true,\n",
    "  \"use_sliding_window\": false,\n",
    "  \"vocab_size\": 151936\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c2ccd0c-ff11-4308-b755-2727b59bf773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'total_size': 8044936192},\n",
       " 'weight_map': {'model.embed_tokens.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.0.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.1.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.10.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.11.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.12.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.13.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.14.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.15.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.15.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.15.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.15.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.16.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.16.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.17.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.18.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.19.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.2.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.2.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.20.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.20.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.21.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.22.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.23.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.24.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.25.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.26.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.27.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.28.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.29.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.3.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.3.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.30.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.30.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.31.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.32.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.33.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.input_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.mlp.down_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.mlp.up_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.post_attention_layernorm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.34.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.input_layernorm.weight': 'model-00003-of-00003.safetensors',\n",
       "  'model.layers.35.mlp.down_proj.weight': 'model-00003-of-00003.safetensors',\n",
       "  'model.layers.35.mlp.gate_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.mlp.up_proj.weight': 'model-00003-of-00003.safetensors',\n",
       "  'model.layers.35.post_attention_layernorm.weight': 'model-00003-of-00003.safetensors',\n",
       "  'model.layers.35.self_attn.k_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.self_attn.k_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.self_attn.o_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.self_attn.q_norm.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.self_attn.q_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.35.self_attn.v_proj.weight': 'model-00002-of-00003.safetensors',\n",
       "  'model.layers.4.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.4.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.5.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.6.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.7.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.8.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.input_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.mlp.down_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.mlp.gate_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.mlp.up_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.post_attention_layernorm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.self_attn.k_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.self_attn.k_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.self_attn.o_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.self_attn.q_norm.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.self_attn.q_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.layers.9.self_attn.v_proj.weight': 'model-00001-of-00003.safetensors',\n",
       "  'model.norm.weight': 'model-00003-of-00003.safetensors'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfe49c9-76fd-4a5a-a18a-68846db03cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0388f5-7c15-4c96-95e8-3e581837c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = safetensors.torch.load_file(Path(prefix, \"model-00001-of-00003.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5540b2d-a689-4e84-8a93-21a6946c0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "st2 = safetensors.torch.load_file(Path(prefix, \"model-00002-of-00003.safetensors\"))\n",
    "st3 = safetensors.torch.load_file(Path(prefix, \"model-00003-of-00003.safetensors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9750bed9-c664-4d58-9ad1-9fc875d748b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model.layers.35.input_layernorm.weight', 'model.layers.35.mlp.down_proj.weight', 'model.layers.35.mlp.up_proj.weight', 'model.layers.35.post_attention_layernorm.weight', 'model.norm.weight'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e743ea7-b7de-4593-91b4-d07fcb154695",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Qwen3Model' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m[\u001b[32m9\u001b[39m].mlp.down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/ctm/lib/python3.12/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Qwen3Model' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "model.layers[9].mlp.down_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff34ff76-2928-4ba0-a33b-e235b29687fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerBlock(\n",
       "  (att): GroupedQueryAttention(\n",
       "    (W_query): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "    (W_key): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "    (W_value): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "    (out_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "    (q_norm): RMSNorm()\n",
       "    (k_norm): RMSNorm()\n",
       "  )\n",
       "  (ff): FeedForward(\n",
       "    (fc1): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "    (fc2): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "    (fc3): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "  )\n",
       "  (norm1): RMSNorm()\n",
       "  (norm2): RMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trf_blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "242353fb-fb89-4c32-b82f-cb16a2618f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "st1.update(st2)\n",
    "st1.update(st3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18548384-69e9-425a-9d3b-9eab2354eb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model uses weight tying.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b850b7e5-058c-4172-acfc-581d5130ec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3Model(\n",
       "  (tok_emb): Embedding(151936, 2560)\n",
       "  (trf_blocks): ModuleList(\n",
       "    (0-35): 36 x TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_query): Linear(in_features=2560, out_features=4096, bias=False)\n",
       "        (W_key): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "        (W_value): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "        (out_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
       "        (q_norm): RMSNorm()\n",
       "        (k_norm): RMSNorm()\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "        (fc2): Linear(in_features=2560, out_features=9728, bias=False)\n",
       "        (fc3): Linear(in_features=9728, out_features=2560, bias=False)\n",
       "      )\n",
       "      (norm1): RMSNorm()\n",
       "      (norm2): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm()\n",
       "  (out_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2287990-6921-4211-8c72-5a7bc69cefeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen3Model(\n",
      "  (tok_emb): Embedding(151936, 2560)\n",
      "  (trf_blocks): ModuleList(\n",
      "    (0-35): 36 x TransformerBlock(\n",
      "      (att): GroupedQueryAttention(\n",
      "        (W_query): Linear(in_features=2560, out_features=4096, bias=False)\n",
      "        (W_key): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "        (W_value): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "        (out_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
      "        (q_norm): RMSNorm()\n",
      "        (k_norm): RMSNorm()\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (fc1): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "        (fc2): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "        (fc3): Linear(in_features=9728, out_features=2560, bias=False)\n",
      "      )\n",
      "      (norm1): RMSNorm()\n",
      "      (norm2): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (final_norm): RMSNorm()\n",
      "  (out_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf925577-043b-4996-9a81-d7b86ed8a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34196958-dd2c-49f1-ad81-4319c002f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, LoraConfig(peft_type=TaskType.CAUSAL_LM, r=16, lora_alpha=32, target_modules=[\"fc1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a44c21-c8c3-46a8-9ce5-de871c768a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen3Model(\n",
      "      (tok_emb): Embedding(151936, 2560)\n",
      "      (trf_blocks): ModuleList(\n",
      "        (0-35): 36 x TransformerBlock(\n",
      "          (att): GroupedQueryAttention(\n",
      "            (W_query): Linear(in_features=2560, out_features=4096, bias=False)\n",
      "            (W_key): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "            (W_value): Linear(in_features=2560, out_features=1024, bias=False)\n",
      "            (out_proj): Linear(in_features=4096, out_features=2560, bias=False)\n",
      "            (q_norm): RMSNorm()\n",
      "            (k_norm): RMSNorm()\n",
      "          )\n",
      "          (ff): FeedForward(\n",
      "            (fc1): lora.Linear(\n",
      "              (base_layer): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "              (lora_dropout): ModuleDict(\n",
      "                (default): Identity()\n",
      "              )\n",
      "              (lora_A): ModuleDict(\n",
      "                (default): Linear(in_features=2560, out_features=16, bias=False)\n",
      "              )\n",
      "              (lora_B): ModuleDict(\n",
      "                (default): Linear(in_features=16, out_features=9728, bias=False)\n",
      "              )\n",
      "              (lora_embedding_A): ParameterDict()\n",
      "              (lora_embedding_B): ParameterDict()\n",
      "              (lora_magnitude_vector): ModuleDict()\n",
      "            )\n",
      "            (fc2): Linear(in_features=2560, out_features=9728, bias=False)\n",
      "            (fc3): Linear(in_features=9728, out_features=2560, bias=False)\n",
      "          )\n",
      "          (norm1): RMSNorm()\n",
      "          (norm2): RMSNorm()\n",
      "        )\n",
      "      )\n",
      "      (final_norm): RMSNorm()\n",
      "      (out_head): Linear(in_features=2560, out_features=151936, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96573794-a5a1-42b9-9160-1c81f685658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_emb.weight False\n",
      "trf_blocks.0.att.W_query.weight False\n",
      "trf_blocks.0.att.W_key.weight False\n",
      "trf_blocks.0.att.W_value.weight False\n",
      "trf_blocks.0.att.out_proj.weight False\n",
      "trf_blocks.0.att.q_norm.scale False\n",
      "trf_blocks.0.att.k_norm.scale False\n",
      "trf_blocks.0.ff.fc1.base_layer.weight False\n",
      "trf_blocks.0.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.0.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.0.ff.fc2.weight False\n",
      "trf_blocks.0.ff.fc3.weight False\n",
      "trf_blocks.0.norm1.scale False\n",
      "trf_blocks.0.norm2.scale False\n",
      "trf_blocks.1.att.W_query.weight False\n",
      "trf_blocks.1.att.W_key.weight False\n",
      "trf_blocks.1.att.W_value.weight False\n",
      "trf_blocks.1.att.out_proj.weight False\n",
      "trf_blocks.1.att.q_norm.scale False\n",
      "trf_blocks.1.att.k_norm.scale False\n",
      "trf_blocks.1.ff.fc1.base_layer.weight False\n",
      "trf_blocks.1.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.1.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.1.ff.fc2.weight False\n",
      "trf_blocks.1.ff.fc3.weight False\n",
      "trf_blocks.1.norm1.scale False\n",
      "trf_blocks.1.norm2.scale False\n",
      "trf_blocks.2.att.W_query.weight False\n",
      "trf_blocks.2.att.W_key.weight False\n",
      "trf_blocks.2.att.W_value.weight False\n",
      "trf_blocks.2.att.out_proj.weight False\n",
      "trf_blocks.2.att.q_norm.scale False\n",
      "trf_blocks.2.att.k_norm.scale False\n",
      "trf_blocks.2.ff.fc1.base_layer.weight False\n",
      "trf_blocks.2.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.2.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.2.ff.fc2.weight False\n",
      "trf_blocks.2.ff.fc3.weight False\n",
      "trf_blocks.2.norm1.scale False\n",
      "trf_blocks.2.norm2.scale False\n",
      "trf_blocks.3.att.W_query.weight False\n",
      "trf_blocks.3.att.W_key.weight False\n",
      "trf_blocks.3.att.W_value.weight False\n",
      "trf_blocks.3.att.out_proj.weight False\n",
      "trf_blocks.3.att.q_norm.scale False\n",
      "trf_blocks.3.att.k_norm.scale False\n",
      "trf_blocks.3.ff.fc1.base_layer.weight False\n",
      "trf_blocks.3.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.3.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.3.ff.fc2.weight False\n",
      "trf_blocks.3.ff.fc3.weight False\n",
      "trf_blocks.3.norm1.scale False\n",
      "trf_blocks.3.norm2.scale False\n",
      "trf_blocks.4.att.W_query.weight False\n",
      "trf_blocks.4.att.W_key.weight False\n",
      "trf_blocks.4.att.W_value.weight False\n",
      "trf_blocks.4.att.out_proj.weight False\n",
      "trf_blocks.4.att.q_norm.scale False\n",
      "trf_blocks.4.att.k_norm.scale False\n",
      "trf_blocks.4.ff.fc1.base_layer.weight False\n",
      "trf_blocks.4.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.4.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.4.ff.fc2.weight False\n",
      "trf_blocks.4.ff.fc3.weight False\n",
      "trf_blocks.4.norm1.scale False\n",
      "trf_blocks.4.norm2.scale False\n",
      "trf_blocks.5.att.W_query.weight False\n",
      "trf_blocks.5.att.W_key.weight False\n",
      "trf_blocks.5.att.W_value.weight False\n",
      "trf_blocks.5.att.out_proj.weight False\n",
      "trf_blocks.5.att.q_norm.scale False\n",
      "trf_blocks.5.att.k_norm.scale False\n",
      "trf_blocks.5.ff.fc1.base_layer.weight False\n",
      "trf_blocks.5.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.5.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.5.ff.fc2.weight False\n",
      "trf_blocks.5.ff.fc3.weight False\n",
      "trf_blocks.5.norm1.scale False\n",
      "trf_blocks.5.norm2.scale False\n",
      "trf_blocks.6.att.W_query.weight False\n",
      "trf_blocks.6.att.W_key.weight False\n",
      "trf_blocks.6.att.W_value.weight False\n",
      "trf_blocks.6.att.out_proj.weight False\n",
      "trf_blocks.6.att.q_norm.scale False\n",
      "trf_blocks.6.att.k_norm.scale False\n",
      "trf_blocks.6.ff.fc1.base_layer.weight False\n",
      "trf_blocks.6.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.6.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.6.ff.fc2.weight False\n",
      "trf_blocks.6.ff.fc3.weight False\n",
      "trf_blocks.6.norm1.scale False\n",
      "trf_blocks.6.norm2.scale False\n",
      "trf_blocks.7.att.W_query.weight False\n",
      "trf_blocks.7.att.W_key.weight False\n",
      "trf_blocks.7.att.W_value.weight False\n",
      "trf_blocks.7.att.out_proj.weight False\n",
      "trf_blocks.7.att.q_norm.scale False\n",
      "trf_blocks.7.att.k_norm.scale False\n",
      "trf_blocks.7.ff.fc1.base_layer.weight False\n",
      "trf_blocks.7.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.7.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.7.ff.fc2.weight False\n",
      "trf_blocks.7.ff.fc3.weight False\n",
      "trf_blocks.7.norm1.scale False\n",
      "trf_blocks.7.norm2.scale False\n",
      "trf_blocks.8.att.W_query.weight False\n",
      "trf_blocks.8.att.W_key.weight False\n",
      "trf_blocks.8.att.W_value.weight False\n",
      "trf_blocks.8.att.out_proj.weight False\n",
      "trf_blocks.8.att.q_norm.scale False\n",
      "trf_blocks.8.att.k_norm.scale False\n",
      "trf_blocks.8.ff.fc1.base_layer.weight False\n",
      "trf_blocks.8.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.8.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.8.ff.fc2.weight False\n",
      "trf_blocks.8.ff.fc3.weight False\n",
      "trf_blocks.8.norm1.scale False\n",
      "trf_blocks.8.norm2.scale False\n",
      "trf_blocks.9.att.W_query.weight False\n",
      "trf_blocks.9.att.W_key.weight False\n",
      "trf_blocks.9.att.W_value.weight False\n",
      "trf_blocks.9.att.out_proj.weight False\n",
      "trf_blocks.9.att.q_norm.scale False\n",
      "trf_blocks.9.att.k_norm.scale False\n",
      "trf_blocks.9.ff.fc1.base_layer.weight False\n",
      "trf_blocks.9.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.9.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.9.ff.fc2.weight False\n",
      "trf_blocks.9.ff.fc3.weight False\n",
      "trf_blocks.9.norm1.scale False\n",
      "trf_blocks.9.norm2.scale False\n",
      "trf_blocks.10.att.W_query.weight False\n",
      "trf_blocks.10.att.W_key.weight False\n",
      "trf_blocks.10.att.W_value.weight False\n",
      "trf_blocks.10.att.out_proj.weight False\n",
      "trf_blocks.10.att.q_norm.scale False\n",
      "trf_blocks.10.att.k_norm.scale False\n",
      "trf_blocks.10.ff.fc1.base_layer.weight False\n",
      "trf_blocks.10.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.10.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.10.ff.fc2.weight False\n",
      "trf_blocks.10.ff.fc3.weight False\n",
      "trf_blocks.10.norm1.scale False\n",
      "trf_blocks.10.norm2.scale False\n",
      "trf_blocks.11.att.W_query.weight False\n",
      "trf_blocks.11.att.W_key.weight False\n",
      "trf_blocks.11.att.W_value.weight False\n",
      "trf_blocks.11.att.out_proj.weight False\n",
      "trf_blocks.11.att.q_norm.scale False\n",
      "trf_blocks.11.att.k_norm.scale False\n",
      "trf_blocks.11.ff.fc1.base_layer.weight False\n",
      "trf_blocks.11.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.11.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.11.ff.fc2.weight False\n",
      "trf_blocks.11.ff.fc3.weight False\n",
      "trf_blocks.11.norm1.scale False\n",
      "trf_blocks.11.norm2.scale False\n",
      "trf_blocks.12.att.W_query.weight False\n",
      "trf_blocks.12.att.W_key.weight False\n",
      "trf_blocks.12.att.W_value.weight False\n",
      "trf_blocks.12.att.out_proj.weight False\n",
      "trf_blocks.12.att.q_norm.scale False\n",
      "trf_blocks.12.att.k_norm.scale False\n",
      "trf_blocks.12.ff.fc1.base_layer.weight False\n",
      "trf_blocks.12.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.12.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.12.ff.fc2.weight False\n",
      "trf_blocks.12.ff.fc3.weight False\n",
      "trf_blocks.12.norm1.scale False\n",
      "trf_blocks.12.norm2.scale False\n",
      "trf_blocks.13.att.W_query.weight False\n",
      "trf_blocks.13.att.W_key.weight False\n",
      "trf_blocks.13.att.W_value.weight False\n",
      "trf_blocks.13.att.out_proj.weight False\n",
      "trf_blocks.13.att.q_norm.scale False\n",
      "trf_blocks.13.att.k_norm.scale False\n",
      "trf_blocks.13.ff.fc1.base_layer.weight False\n",
      "trf_blocks.13.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.13.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.13.ff.fc2.weight False\n",
      "trf_blocks.13.ff.fc3.weight False\n",
      "trf_blocks.13.norm1.scale False\n",
      "trf_blocks.13.norm2.scale False\n",
      "trf_blocks.14.att.W_query.weight False\n",
      "trf_blocks.14.att.W_key.weight False\n",
      "trf_blocks.14.att.W_value.weight False\n",
      "trf_blocks.14.att.out_proj.weight False\n",
      "trf_blocks.14.att.q_norm.scale False\n",
      "trf_blocks.14.att.k_norm.scale False\n",
      "trf_blocks.14.ff.fc1.base_layer.weight False\n",
      "trf_blocks.14.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.14.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.14.ff.fc2.weight False\n",
      "trf_blocks.14.ff.fc3.weight False\n",
      "trf_blocks.14.norm1.scale False\n",
      "trf_blocks.14.norm2.scale False\n",
      "trf_blocks.15.att.W_query.weight False\n",
      "trf_blocks.15.att.W_key.weight False\n",
      "trf_blocks.15.att.W_value.weight False\n",
      "trf_blocks.15.att.out_proj.weight False\n",
      "trf_blocks.15.att.q_norm.scale False\n",
      "trf_blocks.15.att.k_norm.scale False\n",
      "trf_blocks.15.ff.fc1.base_layer.weight False\n",
      "trf_blocks.15.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.15.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.15.ff.fc2.weight False\n",
      "trf_blocks.15.ff.fc3.weight False\n",
      "trf_blocks.15.norm1.scale False\n",
      "trf_blocks.15.norm2.scale False\n",
      "trf_blocks.16.att.W_query.weight False\n",
      "trf_blocks.16.att.W_key.weight False\n",
      "trf_blocks.16.att.W_value.weight False\n",
      "trf_blocks.16.att.out_proj.weight False\n",
      "trf_blocks.16.att.q_norm.scale False\n",
      "trf_blocks.16.att.k_norm.scale False\n",
      "trf_blocks.16.ff.fc1.base_layer.weight False\n",
      "trf_blocks.16.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.16.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.16.ff.fc2.weight False\n",
      "trf_blocks.16.ff.fc3.weight False\n",
      "trf_blocks.16.norm1.scale False\n",
      "trf_blocks.16.norm2.scale False\n",
      "trf_blocks.17.att.W_query.weight False\n",
      "trf_blocks.17.att.W_key.weight False\n",
      "trf_blocks.17.att.W_value.weight False\n",
      "trf_blocks.17.att.out_proj.weight False\n",
      "trf_blocks.17.att.q_norm.scale False\n",
      "trf_blocks.17.att.k_norm.scale False\n",
      "trf_blocks.17.ff.fc1.base_layer.weight False\n",
      "trf_blocks.17.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.17.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.17.ff.fc2.weight False\n",
      "trf_blocks.17.ff.fc3.weight False\n",
      "trf_blocks.17.norm1.scale False\n",
      "trf_blocks.17.norm2.scale False\n",
      "trf_blocks.18.att.W_query.weight False\n",
      "trf_blocks.18.att.W_key.weight False\n",
      "trf_blocks.18.att.W_value.weight False\n",
      "trf_blocks.18.att.out_proj.weight False\n",
      "trf_blocks.18.att.q_norm.scale False\n",
      "trf_blocks.18.att.k_norm.scale False\n",
      "trf_blocks.18.ff.fc1.base_layer.weight False\n",
      "trf_blocks.18.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.18.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.18.ff.fc2.weight False\n",
      "trf_blocks.18.ff.fc3.weight False\n",
      "trf_blocks.18.norm1.scale False\n",
      "trf_blocks.18.norm2.scale False\n",
      "trf_blocks.19.att.W_query.weight False\n",
      "trf_blocks.19.att.W_key.weight False\n",
      "trf_blocks.19.att.W_value.weight False\n",
      "trf_blocks.19.att.out_proj.weight False\n",
      "trf_blocks.19.att.q_norm.scale False\n",
      "trf_blocks.19.att.k_norm.scale False\n",
      "trf_blocks.19.ff.fc1.base_layer.weight False\n",
      "trf_blocks.19.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.19.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.19.ff.fc2.weight False\n",
      "trf_blocks.19.ff.fc3.weight False\n",
      "trf_blocks.19.norm1.scale False\n",
      "trf_blocks.19.norm2.scale False\n",
      "trf_blocks.20.att.W_query.weight False\n",
      "trf_blocks.20.att.W_key.weight False\n",
      "trf_blocks.20.att.W_value.weight False\n",
      "trf_blocks.20.att.out_proj.weight False\n",
      "trf_blocks.20.att.q_norm.scale False\n",
      "trf_blocks.20.att.k_norm.scale False\n",
      "trf_blocks.20.ff.fc1.base_layer.weight False\n",
      "trf_blocks.20.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.20.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.20.ff.fc2.weight False\n",
      "trf_blocks.20.ff.fc3.weight False\n",
      "trf_blocks.20.norm1.scale False\n",
      "trf_blocks.20.norm2.scale False\n",
      "trf_blocks.21.att.W_query.weight False\n",
      "trf_blocks.21.att.W_key.weight False\n",
      "trf_blocks.21.att.W_value.weight False\n",
      "trf_blocks.21.att.out_proj.weight False\n",
      "trf_blocks.21.att.q_norm.scale False\n",
      "trf_blocks.21.att.k_norm.scale False\n",
      "trf_blocks.21.ff.fc1.base_layer.weight False\n",
      "trf_blocks.21.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.21.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.21.ff.fc2.weight False\n",
      "trf_blocks.21.ff.fc3.weight False\n",
      "trf_blocks.21.norm1.scale False\n",
      "trf_blocks.21.norm2.scale False\n",
      "trf_blocks.22.att.W_query.weight False\n",
      "trf_blocks.22.att.W_key.weight False\n",
      "trf_blocks.22.att.W_value.weight False\n",
      "trf_blocks.22.att.out_proj.weight False\n",
      "trf_blocks.22.att.q_norm.scale False\n",
      "trf_blocks.22.att.k_norm.scale False\n",
      "trf_blocks.22.ff.fc1.base_layer.weight False\n",
      "trf_blocks.22.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.22.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.22.ff.fc2.weight False\n",
      "trf_blocks.22.ff.fc3.weight False\n",
      "trf_blocks.22.norm1.scale False\n",
      "trf_blocks.22.norm2.scale False\n",
      "trf_blocks.23.att.W_query.weight False\n",
      "trf_blocks.23.att.W_key.weight False\n",
      "trf_blocks.23.att.W_value.weight False\n",
      "trf_blocks.23.att.out_proj.weight False\n",
      "trf_blocks.23.att.q_norm.scale False\n",
      "trf_blocks.23.att.k_norm.scale False\n",
      "trf_blocks.23.ff.fc1.base_layer.weight False\n",
      "trf_blocks.23.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.23.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.23.ff.fc2.weight False\n",
      "trf_blocks.23.ff.fc3.weight False\n",
      "trf_blocks.23.norm1.scale False\n",
      "trf_blocks.23.norm2.scale False\n",
      "trf_blocks.24.att.W_query.weight False\n",
      "trf_blocks.24.att.W_key.weight False\n",
      "trf_blocks.24.att.W_value.weight False\n",
      "trf_blocks.24.att.out_proj.weight False\n",
      "trf_blocks.24.att.q_norm.scale False\n",
      "trf_blocks.24.att.k_norm.scale False\n",
      "trf_blocks.24.ff.fc1.base_layer.weight False\n",
      "trf_blocks.24.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.24.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.24.ff.fc2.weight False\n",
      "trf_blocks.24.ff.fc3.weight False\n",
      "trf_blocks.24.norm1.scale False\n",
      "trf_blocks.24.norm2.scale False\n",
      "trf_blocks.25.att.W_query.weight False\n",
      "trf_blocks.25.att.W_key.weight False\n",
      "trf_blocks.25.att.W_value.weight False\n",
      "trf_blocks.25.att.out_proj.weight False\n",
      "trf_blocks.25.att.q_norm.scale False\n",
      "trf_blocks.25.att.k_norm.scale False\n",
      "trf_blocks.25.ff.fc1.base_layer.weight False\n",
      "trf_blocks.25.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.25.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.25.ff.fc2.weight False\n",
      "trf_blocks.25.ff.fc3.weight False\n",
      "trf_blocks.25.norm1.scale False\n",
      "trf_blocks.25.norm2.scale False\n",
      "trf_blocks.26.att.W_query.weight False\n",
      "trf_blocks.26.att.W_key.weight False\n",
      "trf_blocks.26.att.W_value.weight False\n",
      "trf_blocks.26.att.out_proj.weight False\n",
      "trf_blocks.26.att.q_norm.scale False\n",
      "trf_blocks.26.att.k_norm.scale False\n",
      "trf_blocks.26.ff.fc1.base_layer.weight False\n",
      "trf_blocks.26.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.26.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.26.ff.fc2.weight False\n",
      "trf_blocks.26.ff.fc3.weight False\n",
      "trf_blocks.26.norm1.scale False\n",
      "trf_blocks.26.norm2.scale False\n",
      "trf_blocks.27.att.W_query.weight False\n",
      "trf_blocks.27.att.W_key.weight False\n",
      "trf_blocks.27.att.W_value.weight False\n",
      "trf_blocks.27.att.out_proj.weight False\n",
      "trf_blocks.27.att.q_norm.scale False\n",
      "trf_blocks.27.att.k_norm.scale False\n",
      "trf_blocks.27.ff.fc1.base_layer.weight False\n",
      "trf_blocks.27.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.27.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.27.ff.fc2.weight False\n",
      "trf_blocks.27.ff.fc3.weight False\n",
      "trf_blocks.27.norm1.scale False\n",
      "trf_blocks.27.norm2.scale False\n",
      "trf_blocks.28.att.W_query.weight False\n",
      "trf_blocks.28.att.W_key.weight False\n",
      "trf_blocks.28.att.W_value.weight False\n",
      "trf_blocks.28.att.out_proj.weight False\n",
      "trf_blocks.28.att.q_norm.scale False\n",
      "trf_blocks.28.att.k_norm.scale False\n",
      "trf_blocks.28.ff.fc1.base_layer.weight False\n",
      "trf_blocks.28.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.28.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.28.ff.fc2.weight False\n",
      "trf_blocks.28.ff.fc3.weight False\n",
      "trf_blocks.28.norm1.scale False\n",
      "trf_blocks.28.norm2.scale False\n",
      "trf_blocks.29.att.W_query.weight False\n",
      "trf_blocks.29.att.W_key.weight False\n",
      "trf_blocks.29.att.W_value.weight False\n",
      "trf_blocks.29.att.out_proj.weight False\n",
      "trf_blocks.29.att.q_norm.scale False\n",
      "trf_blocks.29.att.k_norm.scale False\n",
      "trf_blocks.29.ff.fc1.base_layer.weight False\n",
      "trf_blocks.29.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.29.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.29.ff.fc2.weight False\n",
      "trf_blocks.29.ff.fc3.weight False\n",
      "trf_blocks.29.norm1.scale False\n",
      "trf_blocks.29.norm2.scale False\n",
      "trf_blocks.30.att.W_query.weight False\n",
      "trf_blocks.30.att.W_key.weight False\n",
      "trf_blocks.30.att.W_value.weight False\n",
      "trf_blocks.30.att.out_proj.weight False\n",
      "trf_blocks.30.att.q_norm.scale False\n",
      "trf_blocks.30.att.k_norm.scale False\n",
      "trf_blocks.30.ff.fc1.base_layer.weight False\n",
      "trf_blocks.30.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.30.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.30.ff.fc2.weight False\n",
      "trf_blocks.30.ff.fc3.weight False\n",
      "trf_blocks.30.norm1.scale False\n",
      "trf_blocks.30.norm2.scale False\n",
      "trf_blocks.31.att.W_query.weight False\n",
      "trf_blocks.31.att.W_key.weight False\n",
      "trf_blocks.31.att.W_value.weight False\n",
      "trf_blocks.31.att.out_proj.weight False\n",
      "trf_blocks.31.att.q_norm.scale False\n",
      "trf_blocks.31.att.k_norm.scale False\n",
      "trf_blocks.31.ff.fc1.base_layer.weight False\n",
      "trf_blocks.31.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.31.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.31.ff.fc2.weight False\n",
      "trf_blocks.31.ff.fc3.weight False\n",
      "trf_blocks.31.norm1.scale False\n",
      "trf_blocks.31.norm2.scale False\n",
      "trf_blocks.32.att.W_query.weight False\n",
      "trf_blocks.32.att.W_key.weight False\n",
      "trf_blocks.32.att.W_value.weight False\n",
      "trf_blocks.32.att.out_proj.weight False\n",
      "trf_blocks.32.att.q_norm.scale False\n",
      "trf_blocks.32.att.k_norm.scale False\n",
      "trf_blocks.32.ff.fc1.base_layer.weight False\n",
      "trf_blocks.32.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.32.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.32.ff.fc2.weight False\n",
      "trf_blocks.32.ff.fc3.weight False\n",
      "trf_blocks.32.norm1.scale False\n",
      "trf_blocks.32.norm2.scale False\n",
      "trf_blocks.33.att.W_query.weight False\n",
      "trf_blocks.33.att.W_key.weight False\n",
      "trf_blocks.33.att.W_value.weight False\n",
      "trf_blocks.33.att.out_proj.weight False\n",
      "trf_blocks.33.att.q_norm.scale False\n",
      "trf_blocks.33.att.k_norm.scale False\n",
      "trf_blocks.33.ff.fc1.base_layer.weight False\n",
      "trf_blocks.33.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.33.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.33.ff.fc2.weight False\n",
      "trf_blocks.33.ff.fc3.weight False\n",
      "trf_blocks.33.norm1.scale False\n",
      "trf_blocks.33.norm2.scale False\n",
      "trf_blocks.34.att.W_query.weight False\n",
      "trf_blocks.34.att.W_key.weight False\n",
      "trf_blocks.34.att.W_value.weight False\n",
      "trf_blocks.34.att.out_proj.weight False\n",
      "trf_blocks.34.att.q_norm.scale False\n",
      "trf_blocks.34.att.k_norm.scale False\n",
      "trf_blocks.34.ff.fc1.base_layer.weight False\n",
      "trf_blocks.34.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.34.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.34.ff.fc2.weight False\n",
      "trf_blocks.34.ff.fc3.weight False\n",
      "trf_blocks.34.norm1.scale False\n",
      "trf_blocks.34.norm2.scale False\n",
      "trf_blocks.35.att.W_query.weight False\n",
      "trf_blocks.35.att.W_key.weight False\n",
      "trf_blocks.35.att.W_value.weight False\n",
      "trf_blocks.35.att.out_proj.weight False\n",
      "trf_blocks.35.att.q_norm.scale False\n",
      "trf_blocks.35.att.k_norm.scale False\n",
      "trf_blocks.35.ff.fc1.base_layer.weight False\n",
      "trf_blocks.35.ff.fc1.lora_A.default.weight True\n",
      "trf_blocks.35.ff.fc1.lora_B.default.weight True\n",
      "trf_blocks.35.ff.fc2.weight False\n",
      "trf_blocks.35.ff.fc3.weight False\n",
      "trf_blocks.35.norm1.scale False\n",
      "trf_blocks.35.norm2.scale False\n",
      "final_norm.scale False\n",
      "out_head.weight False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f76ffe81-3a2b-49c2-b6da-29ef44a6940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Qwen3Tokenizer(\n",
    "tokenizer_file_path=\"/Users/john/Downloads/tokenizer.json\",\n",
    "repo_id=None,\n",
    "add_generation_prompt=False,\n",
    "add_thinking=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9420e24b-a56a-497d-a6b8-08fafd0550c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16791817-a0dd-43b0-8a30-0582a69cbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me a short introduction to large language models.\"\n",
    "input_token_ids = tokenizer.encode(prompt)\n",
    "output = model(torch.tensor(input_token_ids, device=device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52ee50c-4593-4404-8403-fa1939010d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_token_ids = generate(\n",
    "    model=model,\n",
    "    idx=torch.tensor(input_token_ids, device=device).unsqueeze(0),\n",
    "    max_new_tokens=512,\n",
    "    context_size=40960,\n",
    "    top_k=1,\n",
    "    temperature=0.\n",
    ")\n",
    "output_text = tokenizer.decode(output_token_ids.squeeze(0).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1327a4-6af9-4359-951e-225737d4a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
